//
//  KaraokeAudioEngine.m
//  AudioSampleBuffer
//
//  Created on 2025/10/14.
//  å‚è€ƒï¼šhttps://blog.csdn.net/weixin_43030741/article/details/103477017
//  ä½¿ç”¨AudioUnit + AUGraphå®ç°å½•éŸ³å’Œè€³è¿”åŠŸèƒ½
//

#import "KaraokeAudioEngine.h"

#define kInputBus 1
#define kOutputBus 0

// é”™è¯¯æ£€æŸ¥å®
static void CheckError(OSStatus error, const char *operation) {
    if (error == noErr) return;
    char errorString[20];
    *(UInt32 *)(errorString + 1) = CFSwapInt32HostToBig(error);
    if (isprint(errorString[1]) && isprint(errorString[2]) &&
        isprint(errorString[3]) && isprint(errorString[4])) {
        errorString[0] = errorString[5] = '\'';
        errorString[6] = '\0';
    } else {
        sprintf(errorString, "%d", (int)error);
    }
    NSLog(@"âŒ Error: %s (%s)", operation, errorString);
}

#pragma mark - RecordingSegment å®ç°

@implementation RecordingSegment

- (instancetype)init {
    self = [super init];
    if (self) {
        _audioData = [NSMutableData data];
        _vocalData = [NSMutableData data];  // ğŸ†• åˆå§‹åŒ–äººå£°æ•°æ®
        _startTime = 0.0;
        _duration = 0.0;
        _isRecorded = YES;
        _appliedEffect = VoiceEffectTypeNone;  // ğŸ†• é»˜è®¤æ— éŸ³æ•ˆ
        _appliedMicVolume = 1.0;  // ğŸ†• é»˜è®¤éº¦å…‹é£éŸ³é‡100%
    }
    return self;
}

- (NSString *)description {
    return [NSString stringWithFormat:@"<RecordingSegment: %.2f~%.2fs, %@, %.2fMB>",
            self.startTime,
            self.startTime + self.duration,
            self.isRecorded ? @"å½•åˆ¶" : @"BGM",
            self.audioData.length / (1024.0 * 1024.0)];
}

@end

#pragma mark - KaraokeAudioEngine

@interface KaraokeAudioEngine ()

// AudioUnitç›¸å…³ï¼ˆé‡æ–°å£°æ˜ä¸ºreadwriteï¼‰
@property (nonatomic, assign, readwrite) AUGraph auGraph;
@property (nonatomic, assign) AudioUnit remoteIOUnit;
@property (nonatomic, assign) AUNode remoteIONode;

// éŸ³é¢‘æ’­æ”¾å™¨ï¼ˆé‡æ–°å£°æ˜ä¸ºreadwriteï¼‰
@property (nonatomic, strong, readwrite) AVAudioPlayer *audioPlayer;

// BGMéŸ³é¢‘æ–‡ä»¶è¯»å–
@property (nonatomic, strong) AVAudioFile *bgmAudioFile;
@property (nonatomic, strong) NSData *bgmPCMData;  // å­˜å‚¨å®Œæ•´çš„BGM PCMæ•°æ®
@property (nonatomic, assign) NSUInteger bgmPCMDataLength;  // PCMæ•°æ®é•¿åº¦ï¼ˆæ ·æœ¬æ•°ï¼‰
@property (atomic, assign) NSUInteger bgmReadPosition;  // å½“å‰è¯»å–ä½ç½®ï¼ˆæ ·æœ¬ç´¢å¼•ï¼‰- ä½¿ç”¨ atomic
@property (nonatomic, assign) BOOL shouldLoopBGM;
@property (nonatomic, assign) float bgmVolume;

// åˆ†æ®µå½•éŸ³ç›¸å…³ï¼ˆé‡æ–°å£°æ˜ä¸ºreadwriteï¼‰
@property (nonatomic, strong) NSMutableArray<RecordingSegment *> *recordingSegmentsInternal;  // å†…éƒ¨å¯å˜æ•°ç»„
@property (nonatomic, strong) RecordingSegment *currentSegment;  // å½“å‰æ­£åœ¨å½•åˆ¶çš„æ®µè½
@property (nonatomic, assign) NSTimeInterval currentSegmentStartTime;  // å½“å‰æ®µè½å¼€å§‹æ—¶é—´
@property (nonatomic, assign, readwrite) BOOL isRecordingPaused;  // å½•éŸ³æš‚åœçŠ¶æ€
@property (nonatomic, copy) NSString *recordingFilePath;  // æœ€ç»ˆåˆæˆæ–‡ä»¶è·¯å¾„

// å½•éŸ³çŠ¶æ€ï¼ˆé‡æ–°å£°æ˜ä¸ºreadwriteï¼‰
@property (nonatomic, assign, readwrite) BOOL isRecording;
@property (nonatomic, assign, readwrite) BOOL isPlaying;

// ğŸ†• é¢„è§ˆæ’­æ”¾ç›¸å…³
@property (nonatomic, strong) AVAudioPlayer *previewPlayer;  // é¢„è§ˆæ’­æ”¾å™¨
@property (nonatomic, strong) NSData *previewAudioData;  // é¢„è§ˆéŸ³é¢‘æ•°æ®ï¼ˆç¼“å­˜ï¼‰
@property (nonatomic, copy) void (^previewCompletion)(NSError *error);  // é¢„è§ˆæ’­æ”¾å®Œæˆå›è°ƒ

// æ··éŸ³ç¼“å†²åŒºï¼ˆé¢„åˆ†é…ï¼Œé¿å…å®æ—¶ malloc/freeï¼‰
@property (nonatomic, assign) SInt16 *mixBuffer;
@property (nonatomic, assign) UInt32 mixBufferSize;

// VUè¡¨æ›´æ–°èŠ‚æµï¼ˆé¿å…è¿‡äºé¢‘ç¹çš„ä¸»çº¿ç¨‹è°ƒåº¦ï¼‰
@property (nonatomic, assign) int vuUpdateCounter;

// è€³è¿”æ§åˆ¶ï¼ˆé‡æ–°å£°æ˜ä¸ºreadwriteï¼‰
@property (nonatomic, assign, readwrite) BOOL enableEarReturn;
@property (nonatomic, assign, readwrite) float earReturnVolume;
@property (nonatomic, assign, readwrite) float microphoneVolume;

// éŸ³æ•ˆå¤„ç†å™¨ï¼ˆé‡æ–°å£°æ˜ä¸ºreadwriteï¼‰
@property (nonatomic, strong, readwrite) VoiceEffectProcessor *voiceEffectProcessor;

@end

@implementation KaraokeAudioEngine

// ğŸ†• å½•éŸ³æ®µè½çš„getter - è¿”å›ä¸å¯å˜å‰¯æœ¬
- (NSArray<RecordingSegment *> *)recordingSegments {
    return [self.recordingSegmentsInternal copy];
}

- (instancetype)init {
    self = [super init];
    if (self) {
        NSLog(@"ğŸ”§ KaraokeAudioEngine init å¼€å§‹");
        
        // é»˜è®¤è®¾ç½®
        _enableEarReturn = YES;
        _earReturnVolume = 0.5;
        _microphoneVolume = 1.0;
        _bgmVolume = 0.3;  // é»˜è®¤BGMéŸ³é‡30%
        _bgmReadPosition = 0;
        _shouldLoopBGM = NO;  // ä¸å¾ªç¯æ’­æ”¾
        
        // ğŸ†• åˆå§‹åŒ–åˆ†æ®µå½•éŸ³
        _recordingSegmentsInternal = [NSMutableArray array];
        _currentSegment = nil;
        _currentSegmentStartTime = 0.0;
        _isRecordingPaused = NO;
        
        // é¢„åˆ†é…æ··éŸ³ç¼“å†²åŒºï¼ˆé¿å…å®æ—¶ malloc/freeï¼‰
        // 44100 Hz, æ¯æ¬¡å›è°ƒçº¦ 5-10msï¼Œæœ€å¤§çº¦ 512 samples
        _mixBufferSize = 2048;  // é¢„ç•™è¶³å¤Ÿç©ºé—´
        _mixBuffer = (SInt16 *)malloc(_mixBufferSize * sizeof(SInt16));
        if (!_mixBuffer) {
            NSLog(@"âŒ æ— æ³•åˆ†é…æ··éŸ³ç¼“å†²åŒº");
            return nil;
        }
        NSLog(@"âœ… é¢„åˆ†é…æ··éŸ³ç¼“å†²åŒº: %u samples", _mixBufferSize);
        
        // VUè¡¨æ›´æ–°è®¡æ•°å™¨
        _vuUpdateCounter = 0;
        
        NSLog(@"ğŸ”§ Step 1: initAudioSession");
        [self initAudioSession];
        
        // åˆå§‹åŒ–éŸ³æ•ˆå¤„ç†å™¨
        AVAudioSession *audioSession = [AVAudioSession sharedInstance];
        double systemSampleRate = audioSession.sampleRate;
        _voiceEffectProcessor = [[VoiceEffectProcessor alloc] initWithSampleRate:systemSampleRate];
        [_voiceEffectProcessor setPresetEffect:VoiceEffectTypeNone];  // é»˜è®¤æ— éŸ³æ•ˆ
        NSLog(@"âœ… éŸ³æ•ˆå¤„ç†å™¨å·²åˆå§‹åŒ–");
        
        NSLog(@"ğŸ”§ Step 2: setupAudioUnit");
        [self setupAudioUnit];
        
        NSLog(@"âœ… KaraokeAudioEngineåˆå§‹åŒ–å®Œæˆï¼ˆåˆ†æ®µå½•éŸ³æ¨¡å¼ï¼Œæ”¯æŒè·³è½¬å’Œå›é€€ï¼‰");
    }
    return self;
}

#pragma mark - AudioSessionåˆå§‹åŒ–

- (void)initAudioSession {
    AVAudioSession *audioSession = [AVAudioSession sharedInstance];
    NSError *error;
    
    // ğŸ”§ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶è®¾ç½®é‡‡æ ·ç‡ä¸º 44.1 kHz
    // ç­–ç•¥ï¼šå…ˆåœç”¨ï¼Œè®¾ç½®å‚æ•°ï¼Œå†æ¿€æ´»
    
    // 1. å…ˆåœç”¨ AudioSessionï¼ˆå¦‚æœå·²æ¿€æ´»ï¼‰
    [audioSession setActive:NO error:&error];
    if (error) {
        NSLog(@"âš ï¸ åœç”¨AudioSessionå¤±è´¥: %@", error.localizedDescription);
        error = nil;
    }
    
    // 2. è®¾ç½®é‡‡æ ·ç‡ï¼ˆå¿…é¡»åœ¨ category ä¹‹å‰ï¼‰
    [audioSession setPreferredSampleRate:44100.0 error:&error];
    if (error) {
        NSLog(@"âš ï¸ è®¾ç½®é‡‡æ ·ç‡å¤±è´¥: %@", error.localizedDescription);
        error = nil;
    } else {
        NSLog(@"âœ… è®¾ç½®é¦–é€‰é‡‡æ ·ç‡: 44100 Hz");
    }
    
    // 3. è®¾ç½®ä¸ºæ’­æ”¾å’Œå½•éŸ³æ¨¡å¼
    // å…³é”®ï¼šä½¿ç”¨MixWithOthersè®©BGMå’Œéº¦å…‹é£åˆ†ç¦»ï¼Œé¿å…éº¦å…‹é£æ•è·BGM
    [audioSession setCategory:AVAudioSessionCategoryPlayAndRecord
                  withOptions:AVAudioSessionCategoryOptionDefaultToSpeaker | 
                              AVAudioSessionCategoryOptionMixWithOthers |  // å…è®¸æ··éŸ³ä½†ä¸æ•è·å…¶ä»–éŸ³é¢‘
                              AVAudioSessionCategoryOptionAllowBluetooth
                        error:&error];
    
    if (error) {
        NSLog(@"âŒ è®¾ç½®AudioSession categoryå¤±è´¥: %@", error.localizedDescription);
        error = nil;
    }
    
    // 4. å†æ¬¡å¼ºåˆ¶è®¾ç½®é‡‡æ ·ç‡ï¼ˆæŸäº›è®¾å¤‡åœ¨ setCategory åä¼šé‡ç½®ï¼‰
    [audioSession setPreferredSampleRate:44100.0 error:&error];
    if (error) {
        NSLog(@"âš ï¸ é‡æ–°è®¾ç½®é‡‡æ ·ç‡å¤±è´¥: %@", error.localizedDescription);
        error = nil;
    }
    
    // 5. è®¾ç½® IO ç¼“å†²åŒºæ—¶é•¿
    [audioSession setPreferredIOBufferDuration:0.005 error:&error];
    if (error) {
        NSLog(@"âš ï¸ è®¾ç½®buffer durationå¤±è´¥: %@", error.localizedDescription);
        error = nil;
    }
    
    // 6. æ¿€æ´» AudioSession
    [audioSession setActive:YES error:&error];
    if (error) {
        NSLog(@"âŒ æ¿€æ´»AudioSessionå¤±è´¥: %@", error.localizedDescription);
    } else {
        // éªŒè¯å®é™…é‡‡æ ·ç‡
        double actualSampleRate = audioSession.sampleRate;
        NSLog(@"âœ… AudioSessioné…ç½®æˆåŠŸï¼ˆMixWithOthersæ¨¡å¼ï¼‰");
        NSLog(@"   é¦–é€‰é‡‡æ ·ç‡: 44100 Hz");
        NSLog(@"   å®é™…é‡‡æ ·ç‡: %.0f Hz", actualSampleRate);
        
        if (fabs(actualSampleRate - 44100.0) > 1.0) {
            NSLog(@"âš ï¸ è­¦å‘Šï¼šå®é™…é‡‡æ ·ç‡ä¸é¢„æœŸä¸ä¸€è‡´ï¼");
            NSLog(@"   è¿™ä¼šå¯¼è‡´ BGM é€Ÿåº¦é”™è¯¯ (æ¯”ä¾‹: %.2fx)", actualSampleRate / 44100.0);
            NSLog(@"   å»ºè®®ï¼šå°†æ‰€æœ‰éŸ³é¢‘ç»„ä»¶æ”¹ä¸º %.0f Hz", actualSampleRate);
        }
    }
}

#pragma mark - AudioUnitè®¾ç½®

- (void)setupAudioUnit {
    NSLog(@"ğŸ”§ setupAudioUnit å¼€å§‹");
    
    // 1. åˆ›å»ºAUGraph
    NSLog(@"ğŸ”§ 1/8: NewAUGraph");
    CheckError(NewAUGraph(&_auGraph), "NewAUGraph");
    
    // 2. æ·»åŠ RemoteIOèŠ‚ç‚¹
    NSLog(@"ğŸ”§ 2/8: AUGraphAddNode");
    AudioComponentDescription ioDescription;
    ioDescription.componentType = kAudioUnitType_Output;
    ioDescription.componentSubType = kAudioUnitSubType_RemoteIO;
    ioDescription.componentManufacturer = kAudioUnitManufacturer_Apple;
    ioDescription.componentFlags = 0;
    ioDescription.componentFlagsMask = 0;
    
    CheckError(AUGraphAddNode(_auGraph, &ioDescription, &_remoteIONode), "AUGraphAddNode");
    
    // 3. æ‰“å¼€AUGraph
    NSLog(@"ğŸ”§ 3/8: AUGraphOpen");
    CheckError(AUGraphOpen(_auGraph), "AUGraphOpen");
    
    // 4. è·å–RemoteIO Unit
    NSLog(@"ğŸ”§ 4/8: AUGraphNodeInfo");
    CheckError(AUGraphNodeInfo(_auGraph, _remoteIONode, NULL, &_remoteIOUnit), "AUGraphNodeInfo");
    
    // 5. å¯ç”¨å½•éŸ³ï¼ˆInputï¼‰
    NSLog(@"ğŸ”§ 5/8: Enable Input");
    UInt32 enableIO = 1;
    CheckError(AudioUnitSetProperty(_remoteIOUnit,
                                   kAudioOutputUnitProperty_EnableIO,
                                   kAudioUnitScope_Input,
                                   kInputBus,
                                   &enableIO,
                                   sizeof(enableIO)),
              "Enable input");
    
    // 6. å¯ç”¨æ’­æ”¾ï¼ˆOutputï¼‰
    NSLog(@"ğŸ”§ 6/8: Enable Output");
    CheckError(AudioUnitSetProperty(_remoteIOUnit,
                                   kAudioOutputUnitProperty_EnableIO,
                                   kAudioUnitScope_Output,
                                   kOutputBus,
                                   &enableIO,
                                   sizeof(enableIO)),
              "Enable output");
    
    // 7. è®¾ç½®éŸ³é¢‘æ ¼å¼
    NSLog(@"ğŸ”§ 7/8: Set Audio Format");
    
    // ğŸ”§ åŠ¨æ€è·å–ç³»ç»Ÿå®é™…é‡‡æ ·ç‡
    AVAudioSession *audioSession = [AVAudioSession sharedInstance];
    double actualSampleRate = audioSession.sampleRate;
    
    // å¦‚æœç³»ç»Ÿé‡‡æ ·ç‡ä¸æ˜¯ 44.1kï¼Œä½¿ç”¨ç³»ç»Ÿé‡‡æ ·ç‡
    double targetSampleRate = 44100.0;
    if (fabs(actualSampleRate - 44100.0) > 1.0) {
        NSLog(@"âš ï¸ ç³»ç»Ÿä¸æ”¯æŒ 44.1kHzï¼Œä½¿ç”¨ç³»ç»Ÿé‡‡æ ·ç‡: %.0f Hz", actualSampleRate);
        targetSampleRate = actualSampleRate;
    }
    
    AudioStreamBasicDescription audioFormat;
    audioFormat.mSampleRate = targetSampleRate;
    audioFormat.mFormatID = kAudioFormatLinearPCM;
    audioFormat.mFormatFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagIsPacked;
    audioFormat.mFramesPerPacket = 1;
    audioFormat.mChannelsPerFrame = 1;
    audioFormat.mBitsPerChannel = 16;
    audioFormat.mBytesPerPacket = 2;
    audioFormat.mBytesPerFrame = 2;
    
    NSLog(@"   ä½¿ç”¨é‡‡æ ·ç‡: %.0f Hz", targetSampleRate);
    
    // è®¾ç½®è¾“å…¥æ ¼å¼
    CheckError(AudioUnitSetProperty(_remoteIOUnit,
                                   kAudioUnitProperty_StreamFormat,
                                   kAudioUnitScope_Output,
                                   kInputBus,
                                   &audioFormat,
                                   sizeof(audioFormat)),
              "Set input format");
    
    // è®¾ç½®è¾“å‡ºæ ¼å¼
    CheckError(AudioUnitSetProperty(_remoteIOUnit,
                                   kAudioUnitProperty_StreamFormat,
                                   kAudioUnitScope_Input,
                                   kOutputBus,
                                   &audioFormat,
                                   sizeof(audioFormat)),
              "Set output format");
    
    // 8. è®¾ç½®è¾“å…¥å›è°ƒï¼ˆç”¨äºè€³è¿”ï¼Œä»è¾“å…¥è·å–æ•°æ®å¹¶è¾“å‡ºï¼‰
    NSLog(@"ğŸ”§ 8/8: Set Render Callback");
    // æ³¨æ„ï¼šè¿™ä¸ªå›è°ƒå®é™…ä¸Šæ˜¯è¾“å‡ºå›è°ƒï¼Œä¼šè‡ªåŠ¨ä»è¾“å…¥è·å–æ•°æ®
    AURenderCallbackStruct renderCallback;
    renderCallback.inputProc = RenderCallback;
    renderCallback.inputProcRefCon = (__bridge void *)self;
    
    CheckError(AUGraphSetNodeInputCallback(_auGraph,
                                          _remoteIONode,
                                          kOutputBus,
                                          &renderCallback),
              "Set render callback");
    
    // 10. åˆå§‹åŒ–AUGraph
    NSLog(@"ğŸ”§ Initialize AUGraph");
    CheckError(AUGraphInitialize(_auGraph), "AUGraphInitialize");
    
    NSLog(@"âœ… AudioUnitè®¾ç½®å®Œæˆ");
}

#pragma mark - AudioUnitå›è°ƒå‡½æ•°

// æ¸²æŸ“å›è°ƒï¼ˆç»Ÿä¸€å¤„ç†è€³è¿”å’Œå½•éŸ³ï¼‰
// æ³¨æ„ï¼šè¿™ä¸ªå›è°ƒç”±AUGraphSetNodeInputCallbackè§¦å‘ï¼Œç”¨äºå¤„ç†è¾“å‡ºæ•°æ®
// å®ƒä¼šè‡ªåŠ¨ä»éº¦å…‹é£è¾“å…¥è·å–æ•°æ®ï¼Œç„¶åè¾“å‡ºåˆ°æ‰¬å£°å™¨ï¼ˆè€³è¿”ï¼‰
static OSStatus RenderCallback(void *inRefCon,
                               AudioUnitRenderActionFlags *ioActionFlags,
                               const AudioTimeStamp *inTimeStamp,
                               UInt32 inBusNumber,
                               UInt32 inNumberFrames,
                               AudioBufferList *ioData) {
    KaraokeAudioEngine *engine = (__bridge KaraokeAudioEngine *)inRefCon;
    
    // åˆ›å»ºç‹¬ç«‹çš„è¾“å…¥ç¼“å†²åŒºï¼Œé¿å…è¾“å…¥è¾“å‡ºå¾ªç¯
    AudioBufferList inputBufferList;
    inputBufferList.mNumberBuffers = 1;
    inputBufferList.mBuffers[0].mNumberChannels = 1;
    inputBufferList.mBuffers[0].mDataByteSize = inNumberFrames * sizeof(SInt16);
    SInt16 *inputBuffer = (SInt16 *)malloc(inputBufferList.mBuffers[0].mDataByteSize);
    inputBufferList.mBuffers[0].mData = inputBuffer;
    
    if (!inputBuffer) {
        NSLog(@"âŒ æ— æ³•åˆ†é…è¾“å…¥ç¼“å†²åŒº");
        return noErr;
    }
    
    // 1. ä»éº¦å…‹é£è¾“å…¥è·å–æ•°æ®åˆ°ç‹¬ç«‹ç¼“å†²åŒº
    OSStatus status = AudioUnitRender(engine->_remoteIOUnit,
                                     ioActionFlags,
                                     inTimeStamp,
                                     kInputBus,  // ä»è¾“å…¥æ€»çº¿è·å–éº¦å…‹é£æ•°æ®
                                     inNumberFrames,
                                     &inputBufferList);
    
    if (status != noErr) {
        NSLog(@"âŒ RenderCallback AudioUnitRender error: %d", (int)status);
        free(inputBuffer);
        return status;
    }
    
    // 2. è·å–éº¦å…‹é£éŸ³é¢‘æ•°æ®
    UInt32 sampleCount = inputBufferList.mBuffers[0].mDataByteSize / sizeof(SInt16);
    
    // 3. ğŸ†• å¦‚æœæ­£åœ¨å½•éŸ³ä¸”æœªæš‚åœï¼Œå†™å…¥å½“å‰æ®µè½çš„å†…å­˜ç¼“å†²åŒº
    if (engine.isRecording && !engine.isRecordingPaused && engine.currentSegment) {
        // ä½¿ç”¨é¢„åˆ†é…çš„æ··éŸ³ç¼“å†²åŒºï¼ˆé¿å… malloc/freeï¼‰
        SInt16 *mixedSamples = engine->_mixBuffer;
        
        // æ£€æŸ¥ç¼“å†²åŒºå¤§å°æ˜¯å¦è¶³å¤Ÿ
        if (sampleCount <= engine->_mixBufferSize && mixedSamples) {
            // å¤åˆ¶éº¦å…‹é£æ•°æ®å¹¶åº”ç”¨éŸ³é‡ï¼ˆä½¿ç”¨ memcpy + å°±åœ°ä¿®æ”¹ï¼Œæ›´å¿«ï¼‰
            memcpy(mixedSamples, inputBuffer, sampleCount * sizeof(SInt16));
            
            // åº”ç”¨éº¦å…‹é£éŸ³é‡
            float micVol = engine.microphoneVolume;
            if (micVol != 1.0f) {  // ä¼˜åŒ–ï¼šåªåœ¨é 100% æ—¶æ‰è®¡ç®—
                for (UInt32 i = 0; i < sampleCount; i++) {
                    mixedSamples[i] = (SInt16)(mixedSamples[i] * micVol);
                }
            }
            
            // ğŸ”§ Bugä¿®å¤ï¼šä¿å­˜åŸå§‹äººå£°æ•°æ®ï¼ˆåº”ç”¨éŸ³é‡ä½†æœªåº”ç”¨éŸ³æ•ˆï¼‰
            // è¿™æ ·é¢„è§ˆæ—¶å¯ä»¥é‡æ–°åº”ç”¨ä¸åŒçš„éŸ³æ•ˆ
            NSData *vocalChunkData = [NSData dataWithBytes:mixedSamples length:sampleCount * sizeof(SInt16)];
            [engine.currentSegment.vocalData appendData:vocalChunkData];
            
            // åº”ç”¨éŸ³æ•ˆå¤„ç†ï¼ˆåœ¨æ··åˆBGMä¹‹å‰ï¼Œä»…ç”¨äºå½•éŸ³æ–‡ä»¶ï¼‰
            if (engine.voiceEffectProcessor) {
                [engine.voiceEffectProcessor processAudioBuffer:mixedSamples sampleCount:sampleCount];
            }
            
            // å¦‚æœæœ‰BGMï¼Œæ··å…¥BGMæ•°æ®ï¼ˆä»…ç”¨äºå½•éŸ³æ–‡ä»¶ï¼‰
            if (engine.bgmPCMData && engine.bgmPCMDataLength > 0) {
                [engine mixBGMIntoBuffer:mixedSamples sampleCount:sampleCount];
            }
            
            // âœ… å†™å…¥å½“å‰æ®µè½çš„æ··åˆéŸ³é¢‘ç¼“å†²åŒºï¼ˆå¸¦éŸ³æ•ˆ+BGMï¼Œç”¨äºå…¼å®¹æ—§é€»è¾‘ï¼‰
            NSData *mixedChunkData = [NSData dataWithBytes:mixedSamples length:sampleCount * sizeof(SInt16)];
            [engine.currentSegment.audioData appendData:mixedChunkData];
        } else {
            NSLog(@"âš ï¸ æ··éŸ³ç¼“å†²åŒºå¤ªå°: éœ€è¦ %u, å¯ç”¨ %u", sampleCount, engine->_mixBufferSize);
        }
    }
    
    // 4. å¤„ç†è€³è¿”è¾“å‡ºï¼ˆåº”ç”¨éŸ³æ•ˆåè¾“å‡ºäººå£°ï¼Œä¸å«BGMï¼‰
    if (engine.enableEarReturn && ioData) {
        // åˆ›å»ºè€³è¿”ç¼“å†²åŒºï¼ˆåº”ç”¨éŸ³æ•ˆï¼‰
        SInt16 *earReturnBuffer = (SInt16 *)malloc(sampleCount * sizeof(SInt16));
        if (earReturnBuffer) {
            // å¤åˆ¶éº¦å…‹é£æ•°æ®
            memcpy(earReturnBuffer, inputBuffer, sampleCount * sizeof(SInt16));
            
            // åº”ç”¨éº¦å…‹é£éŸ³é‡
            float micVol = engine.microphoneVolume;
            if (micVol != 1.0f) {
                for (UInt32 i = 0; i < sampleCount; i++) {
                    earReturnBuffer[i] = (SInt16)(earReturnBuffer[i] * micVol);
                }
            }
            
            // ğŸµ å…³é”®ä¿®å¤ï¼šå¯¹è€³è¿”ä¹Ÿåº”ç”¨éŸ³æ•ˆå¤„ç†
            if (engine.voiceEffectProcessor) {
                [engine.voiceEffectProcessor processAudioBuffer:earReturnBuffer sampleCount:sampleCount];
            }
            
            // è¾“å‡ºåˆ°è€³è¿”ï¼ˆåº”ç”¨è€³è¿”éŸ³é‡ï¼‰
            float earVolume = engine.earReturnVolume;
            for (int i = 0; i < ioData->mNumberBuffers; i++) {
                SInt16 *samples = (SInt16 *)ioData->mBuffers[i].mData;
                UInt32 bufferSampleCount = ioData->mBuffers[i].mDataByteSize / sizeof(SInt16);
                UInt32 copyCount = MIN(sampleCount, bufferSampleCount);
                
                // è¾“å‡ºå¸¦éŸ³æ•ˆçš„äººå£°
                for (UInt32 j = 0; j < copyCount; j++) {
                    samples[j] = (SInt16)(earReturnBuffer[j] * earVolume);
                }
            }
            
            free(earReturnBuffer);
        }
    } else {
        // å¦‚æœè€³è¿”å…³é—­ï¼Œé™éŸ³è¾“å‡ºï¼ˆä½†ä»ç„¶å½•éŸ³ï¼‰
        for (int i = 0; i < ioData->mNumberBuffers; i++) {
            memset(ioData->mBuffers[i].mData, 0, ioData->mBuffers[i].mDataByteSize);
        }
    }
    
    // 5. è®¡ç®—éŸ³é‡ç”µå¹³ï¼ˆç”¨äºVUè¡¨ï¼‰- ä½¿ç”¨åŸå§‹éº¦å…‹é£æ•°æ®
    // èŠ‚æµï¼šæ¯ 5 æ¬¡å›è°ƒæ‰æ›´æ–°ä¸€æ¬¡ï¼ˆçº¦ 25-50ms æ›´æ–°ä¸€æ¬¡ï¼Œè¶³å¤Ÿæµç•…ï¼‰
    engine->_vuUpdateCounter++;
    if (engine->_vuUpdateCounter >= 5) {
        engine->_vuUpdateCounter = 0;
        
        float sum = 0;
        float peak = 0;
        
        for (UInt32 i = 0; i < sampleCount; i++) {
            float sample = abs(inputBuffer[i]) / 32768.0f;
            sum += sample;
            if (sample > peak) {
                peak = sample;
            }
        }
        
        float avgLevel = sum / sampleCount;
        
        // é€šçŸ¥ä»£ç†æ›´æ–°VUè¡¨ï¼ˆå·²ç»èŠ‚æµï¼Œå‡å°‘ä¸»çº¿ç¨‹å‹åŠ›ï¼‰
        dispatch_async(dispatch_get_main_queue(), ^{
            if ([engine.delegate respondsToSelector:@selector(audioEngineDidUpdateMicrophoneLevel:)]) {
                [engine.delegate audioEngineDidUpdateMicrophoneLevel:avgLevel];
            }
            if ([engine.delegate respondsToSelector:@selector(audioEngineDidUpdatePeakLevel:)]) {
                [engine.delegate audioEngineDidUpdatePeakLevel:peak];
            }
        });
    }
    
    // é‡Šæ”¾è¾“å…¥ç¼“å†²åŒºï¼ˆmixedSamples æ˜¯é¢„åˆ†é…çš„ï¼Œä¸éœ€è¦é‡Šæ”¾ï¼‰
    free(inputBuffer);
    
    return noErr;
}

#pragma mark - BGMæ··éŸ³è¾…åŠ©æ–¹æ³•

// å°†BGMæ•°æ®æ··å…¥ç¼“å†²åŒº - ä¼˜åŒ–ç‰ˆæœ¬
- (void)mixBGMIntoBuffer:(SInt16 *)buffer sampleCount:(UInt32)sampleCount {
    if (!self.bgmPCMData || self.bgmPCMDataLength == 0) {
        return;
    }
    
    const SInt16 *bgmSamples = (const SInt16 *)self.bgmPCMData.bytes;
    NSUInteger currentPos = self.bgmReadPosition;  // è¯»å–ä¸€æ¬¡ï¼Œé¿å…å¤šæ¬¡åŸå­æ“ä½œ
    NSUInteger bgmLength = self.bgmPCMDataLength;
    float volume = self.bgmVolume;
    
    // ğŸ› è¯¦ç»†è°ƒè¯•æ—¥å¿—ï¼ˆé™ä½é¢‘ç‡ï¼Œé¿å…é˜»å¡ï¼‰
    static int callCount = 0;
    
    if (callCount++ % 200 == 0) {  // æ¯ 200 æ¬¡æ‰“å°ä¸€æ¬¡ï¼ˆçº¦ 1 ç§’ï¼‰
        // è·å–ç³»ç»Ÿé‡‡æ ·ç‡ç”¨äºè®¡ç®—æ—¶é•¿
        AVAudioSession *audioSession = [AVAudioSession sharedInstance];
        double systemSampleRate = audioSession.sampleRate;
        
        NSTimeInterval currentTime = (NSTimeInterval)currentPos / systemSampleRate;
        NSTimeInterval totalTime = (NSTimeInterval)bgmLength / systemSampleRate;
        NSLog(@"ğŸµ æ··éŸ³è¯¦æƒ…: pos=%lu/%lu, æ—¶é—´=%.2f/%.2fç§’, samples=%u, è¿›åº¦=%.1f%%", 
              (unsigned long)currentPos, 
              (unsigned long)bgmLength,
              currentTime,
              totalTime,
              sampleCount,
              (currentPos * 100.0 / bgmLength));
    }
    
    // æ£€æŸ¥æ˜¯å¦å·²ç»è¶…å‡ºèŒƒå›´
    if (currentPos >= bgmLength) {
        NSLog(@"âš ï¸ BGMå·²åˆ°è¾¾æœ«å°¾ï¼Œåœæ­¢æ··éŸ³");
        return;
    }
    
    // æ‰¹é‡å¤„ç†ï¼Œå‡å°‘è¾¹ç•Œæ£€æŸ¥
    UInt32 processed = 0;
    
    while (processed < sampleCount) {
        // æ£€æŸ¥æ˜¯å¦åˆ°è¾¾BGMæœ«å°¾
        if (currentPos >= bgmLength) {
            NSLog(@"âš ï¸ BGMåˆ°è¾¾æœ«å°¾: pos=%lu, length=%lu", (unsigned long)currentPos, (unsigned long)bgmLength);
            if (self.shouldLoopBGM) {
                // å¾ªç¯æ’­æ”¾ï¼šé‡ç½®åˆ°å¼€å¤´
                currentPos = 0;
                NSLog(@"ğŸ”„ BGMå¾ªç¯åˆ°å¼€å¤´");
            } else {
                // ä¸å¾ªç¯ï¼šåœæ­¢æ··éŸ³ï¼Œå‰©ä½™éƒ¨åˆ†å¡«å……é™éŸ³
                NSLog(@"ğŸ›‘ BGMç»“æŸï¼Œå‰©ä½™ %u æ ·æœ¬å¡«å……é™éŸ³", sampleCount - processed);
                // å‰©ä½™éƒ¨åˆ†ä¸å†æ··éŸ³ï¼ˆä¿æŒåŸæœ‰äººå£°ï¼‰
                break;
            }
        }
        
        // è®¡ç®—å¯ä»¥è¿ç»­å¤„ç†çš„æ ·æœ¬æ•°ï¼ˆåˆ°BGMç»“æŸæˆ–åˆ°è¯·æ±‚ç»“æŸï¼‰
        UInt32 remainingInBGM = (UInt32)(bgmLength - currentPos);
        UInt32 remainingInBuffer = sampleCount - processed;
        UInt32 batchSize = MIN(remainingInBGM, remainingInBuffer);
        
        // æ‰¹é‡æ··éŸ³ï¼ˆå‡å°‘å¾ªç¯å¼€é”€ï¼‰
        for (UInt32 i = 0; i < batchSize; i++) {
            SInt16 bgmSample = bgmSamples[currentPos + i];
            SInt16 vocalSample = buffer[processed + i];
            
            // ğŸ›ï¸ æ™ºèƒ½æ··éŸ³ï¼šé¢„æµ‹æº¢å‡ºå¹¶åŠ¨æ€è°ƒæ•´
            // ğŸ”Š å½•éŸ³å¢ç›Šï¼šBGM é¢å¤–å¢åŠ  1.5 å€ï¼Œè®©å½•éŸ³ä¸­çš„ BGM æ›´å“äº®
            float recordingGain = 1.5f;  // å¯è°ƒèŠ‚ï¼š1.0-2.0 ä¹‹é—´
            int32_t bgmValue = (int32_t)(bgmSample * volume * recordingGain);
            int32_t mixed = (int32_t)vocalSample + bgmValue;
            
            // è½¯å‰Šæ³¢ï¼šå¦‚æœæ¥è¿‘æº¢å‡ºï¼ŒæŒ‰æ¯”ä¾‹å‹ç¼©
            if (mixed > 32767 || mixed < -32768) {
                // è®¡ç®—å‹ç¼©æ¯”ä¾‹ï¼ˆä¿ç•™ 90% åŠ¨æ€èŒƒå›´ï¼Œé¿å…ç¡¬å‰Šæ³¢ï¼‰
                float compressionRatio = 29490.0f / fabs(mixed);  // 29490 = 32767 * 0.9
                mixed = (int32_t)(mixed * compressionRatio);
            }
            
            buffer[processed + i] = (SInt16)mixed;
        }
        
        currentPos += batchSize;
        processed += batchSize;
    }
    
    // åŸå­æ›´æ–°è¯»å–ä½ç½®ï¼ˆåªæ›´æ–°ä¸€æ¬¡ï¼‰
    self.bgmReadPosition = currentPos;
}

#pragma mark - åˆ†æ®µå½•éŸ³æ§åˆ¶

// ğŸ†• ä»å½“å‰æ’­æ”¾ä½ç½®å¼€å§‹å½•éŸ³
- (void)startRecording {
    NSTimeInterval currentTime = self.currentPlaybackTime;
    [self startRecordingFromTime:currentTime];
}

// ğŸ†• ä»æŒ‡å®šæ—¶é—´å¼€å§‹å½•éŸ³
- (void)startRecordingFromTime:(NSTimeInterval)startTime {
    if (self.isRecording && !self.isRecordingPaused) {
        NSLog(@"âš ï¸ å·²åœ¨å½•éŸ³ä¸­");
        return;
    }
    
    // å¦‚æœä¹‹å‰æš‚åœäº†ï¼Œå…ˆä¿å­˜æš‚åœå‰çš„æ®µè½
    if (self.isRecording && self.isRecordingPaused) {
        [self saveCurrentSegment];
    }
    
    // åˆ›å»ºæ–°çš„å½•éŸ³æ®µè½
    RecordingSegment *newSegment = [[RecordingSegment alloc] init];
    newSegment.startTime = startTime;
    newSegment.isRecorded = YES;  // æ ‡è®°ä¸ºå½•åˆ¶æ®µè½ï¼ˆæœ‰äººå£°ï¼‰
    
    // ğŸ†• ä¿å­˜å½“å‰å½•åˆ¶å‚æ•°
    newSegment.appliedEffect = self.voiceEffectProcessor.effectType;
    newSegment.appliedMicVolume = self.microphoneVolume;
    
    self.currentSegment = newSegment;
    self.currentSegmentStartTime = startTime;
    self.isRecordingPaused = NO;
    
    // å¦‚æœAUGraphæœªå¯åŠ¨ï¼Œå¯åŠ¨å®ƒ
    Boolean isRunning = false;
    AUGraphIsRunning(self.auGraph, &isRunning);
    if (!isRunning) {
        CheckError(AUGraphStart(self.auGraph), "AUGraphStart");
    }
    
    self.isRecording = YES;
    
    NSLog(@"ğŸ¤ å¼€å§‹å½•éŸ³ï¼ˆä» %.2f ç§’å¼€å§‹ï¼‰", startTime);
}

// ğŸ†• æš‚åœå½•éŸ³ï¼ˆBGMç»§ç»­æ’­æ”¾ï¼Œä½†ä¸å†™å…¥äººå£°ï¼‰
- (void)pauseRecording {
    if (!self.isRecording || self.isRecordingPaused) {
        return;
    }
    
    // ä¿å­˜å½“å‰æ®µè½
    [self saveCurrentSegment];
    
    self.isRecordingPaused = YES;
    NSLog(@"â¸ï¸ å½•éŸ³å·²æš‚åœï¼ˆBGMç»§ç»­æ’­æ”¾ï¼‰");
}

// ğŸ†• æ¢å¤å½•éŸ³
- (void)resumeRecording {
    if (!self.isRecording || !self.isRecordingPaused) {
        return;
    }
    
    // ä»å½“å‰æ’­æ”¾ä½ç½®é‡æ–°å¼€å§‹å½•éŸ³
    NSTimeInterval currentTime = self.currentPlaybackTime;
    
    // åˆ›å»ºæ–°æ®µè½
    RecordingSegment *newSegment = [[RecordingSegment alloc] init];
    newSegment.startTime = currentTime;
    newSegment.isRecorded = YES;
    
    // ğŸ”§ Bugä¿®å¤ï¼šè®¾ç½®å½“å‰å½•åˆ¶å‚æ•°
    newSegment.appliedEffect = self.voiceEffectProcessor.effectType;
    newSegment.appliedMicVolume = self.microphoneVolume;
    
    self.currentSegment = newSegment;
    self.currentSegmentStartTime = currentTime;
    self.isRecordingPaused = NO;
    
    NSLog(@"â–¶ï¸ å½•éŸ³å·²æ¢å¤ï¼ˆä» %.2f ç§’å¼€å§‹ï¼‰", currentTime);
}

// ğŸ†• åœæ­¢å½“å‰æ®µè½çš„å½•éŸ³
- (void)stopRecording {
    if (!self.isRecording) {
        return;
    }
    
    NSLog(@"ğŸ›‘ åœæ­¢å½“å‰æ®µè½å½•éŸ³");
    
    // ä¿å­˜å½“å‰æ®µè½
    [self saveCurrentSegment];
    
    // åœæ­¢å½•éŸ³çŠ¶æ€ï¼ˆä½†ä¸åœæ­¢æ’­æ”¾ï¼‰
    self.isRecording = NO;
    self.isRecordingPaused = NO;
    self.currentSegment = nil;
    
    NSLog(@"âœ… å½“å‰æ®µè½å·²ä¿å­˜ï¼Œå…± %lu ä¸ªæ®µè½", (unsigned long)self.recordingSegments.count);
}

// ğŸ†• å®Œæˆæ‰€æœ‰å½•éŸ³ï¼Œåˆæˆæœ€ç»ˆæ–‡ä»¶
- (void)finishRecording {
    if (self.isRecording) {
        [self stopRecording];
    }
    
    if (self.recordingSegmentsInternal.count == 0) {
        NSLog(@"âš ï¸ æ²¡æœ‰å½•éŸ³æ®µè½");
        return;
    }
    
    NSLog(@"ğŸ¬ å¼€å§‹åˆæˆæœ€ç»ˆå½•éŸ³æ–‡ä»¶...");
    
    // 1. åœæ­¢BGMæ’­æ”¾
    if (self.isPlaying) {
        [self stop];
        NSLog(@"ğŸ›‘ BGMæ’­æ”¾å·²åœæ­¢");
    }
    
    // 2. åœæ­¢AUGraph
    CheckError(AUGraphStop(self.auGraph), "AUGraphStop");
    usleep(100 * 1000);  // 100ms å»¶è¿Ÿ
    
    // 3. åˆæˆæ‰€æœ‰æ®µè½
    [self synthesizeFinalRecording];
    
    NSLog(@"âœ… å½•éŸ³å®Œæˆ: %@", self.recordingFilePath);
}

// ä¿å­˜å½“å‰æ®µè½
- (void)saveCurrentSegment {
    if (!self.currentSegment) {
        return;
    }
    
    // è®¡ç®—æ®µè½æ—¶é•¿
    AVAudioSession *audioSession = [AVAudioSession sharedInstance];
    double systemSampleRate = audioSession.sampleRate;
    NSUInteger sampleCount = self.currentSegment.audioData.length / sizeof(SInt16);
    self.currentSegment.duration = (NSTimeInterval)sampleCount / systemSampleRate;
    
    // æ·»åŠ åˆ°æ®µè½æ•°ç»„
    [self.recordingSegmentsInternal addObject:self.currentSegment];
    
    NSLog(@"ğŸ’¾ æ®µè½å·²ä¿å­˜: %.2f~%.2fs (%.2fMB, %@)",
          self.currentSegment.startTime,
          self.currentSegment.startTime + self.currentSegment.duration,
          self.currentSegment.audioData.length / (1024.0 * 1024.0),
          self.currentSegment.isRecorded ? @"å½•åˆ¶" : @"BGM");
    
    // é€šçŸ¥ä»£ç†
    [self notifySegmentsUpdate];
    
    self.currentSegment = nil;
}

#pragma mark - æ®µè½ç®¡ç†

// ğŸ†• è·³è½¬åˆ°æŒ‡å®šæ—¶é—´ï¼ˆè·³è¿‡çš„éƒ¨åˆ†å¡«å……çº¯BGMï¼‰
- (void)jumpToTime:(NSTimeInterval)targetTime {
    NSTimeInterval currentTime = self.currentPlaybackTime;
    
    if (targetTime <= currentTime) {
        NSLog(@"âš ï¸ ç›®æ ‡æ—¶é—´ %.2f å°äºç­‰äºå½“å‰æ—¶é—´ %.2fï¼Œè¯·ä½¿ç”¨rewindToTime", targetTime, currentTime);
        return;
    }
    
    // å¦‚æœæ­£åœ¨å½•éŸ³ï¼Œå…ˆæš‚åœå½“å‰æ®µè½
    if (self.isRecording && !self.isRecordingPaused) {
        [self saveCurrentSegment];
        self.isRecordingPaused = YES;
    }
    
    // è·³è½¬æ’­æ”¾ä½ç½®
    if (self.audioPlayer) {
        self.audioPlayer.currentTime = targetTime;
    }
    
    // æ›´æ–°BGMè¯»å–ä½ç½®
    AVAudioSession *audioSession = [AVAudioSession sharedInstance];
    double systemSampleRate = audioSession.sampleRate;
    self.bgmReadPosition = (NSUInteger)(targetTime * systemSampleRate);
    
    NSLog(@"â­ï¸ è·³è½¬åˆ° %.2f ç§’ï¼ˆè·³è¿‡ %.2f ç§’ï¼‰", targetTime, targetTime - currentTime);
    
    // å¦‚æœæ­£åœ¨å½•éŸ³æ¨¡å¼ï¼Œæ¢å¤å½•éŸ³
    if (self.isRecording && self.isRecordingPaused) {
        [self resumeRecording];
    }
}

// ğŸ†• å›é€€åˆ°æŒ‡å®šæ—¶é—´ï¼ˆåˆ é™¤ä¹‹åçš„æ‰€æœ‰æ®µè½ï¼‰
- (void)rewindToTime:(NSTimeInterval)targetTime {
    NSLog(@"âª å›é€€åˆ° %.2f ç§’", targetTime);
    
    // å¦‚æœæ­£åœ¨å½•éŸ³ï¼Œå…ˆåœæ­¢å½“å‰æ®µè½
    if (self.isRecording && self.currentSegment) {
        self.currentSegment = nil;  // ä¸¢å¼ƒå½“å‰æ®µè½ï¼ˆä¸ä¿å­˜ï¼‰
    }
    
    // åˆ é™¤ç›®æ ‡æ—¶é—´ä¹‹åçš„æ‰€æœ‰æ®µè½
    NSMutableArray *segmentsToKeep = [NSMutableArray array];
    for (RecordingSegment *segment in self.recordingSegmentsInternal) {
        if (segment.startTime < targetTime) {
            // å¦‚æœæ®µè½è·¨è¶Šç›®æ ‡æ—¶é—´ï¼Œéœ€è¦æˆªæ–­
            if (segment.startTime + segment.duration > targetTime) {
                NSTimeInterval newDuration = targetTime - segment.startTime;
                AVAudioSession *audioSession = [AVAudioSession sharedInstance];
                double systemSampleRate = audioSession.sampleRate;
                NSUInteger newSampleCount = (NSUInteger)(newDuration * systemSampleRate);
                NSUInteger newByteLength = newSampleCount * sizeof(SInt16);
                
                if (newByteLength < segment.audioData.length) {
                    [segment.audioData setLength:newByteLength];
                    segment.duration = newDuration;
                    NSLog(@"âœ‚ï¸ æˆªæ–­æ®µè½: %.2f~%.2fs", segment.startTime, targetTime);
                }
            }
            [segmentsToKeep addObject:segment];
        } else {
            NSLog(@"ğŸ—‘ï¸ åˆ é™¤æ®µè½: %@", segment);
        }
    }
    
    self.recordingSegmentsInternal = segmentsToKeep;
    
    // è·³è½¬æ’­æ”¾ä½ç½®
    if (self.audioPlayer) {
        self.audioPlayer.currentTime = targetTime;
    }
    
    // æ›´æ–°BGMè¯»å–ä½ç½®
    AVAudioSession *audioSession = [AVAudioSession sharedInstance];
    double systemSampleRate = audioSession.sampleRate;
    self.bgmReadPosition = (NSUInteger)(targetTime * systemSampleRate);
    
    // é€šçŸ¥ä»£ç†
    [self notifySegmentsUpdate];
    
    NSLog(@"âœ… å›é€€å®Œæˆï¼Œå‰©ä½™ %lu ä¸ªæ®µè½", (unsigned long)self.recordingSegments.count);
}

// ğŸ†• åˆ é™¤æŒ‡å®šæ®µè½
- (void)deleteSegmentAtIndex:(NSInteger)index {
    if (index < 0 || index >= self.recordingSegmentsInternal.count) {
        NSLog(@"âš ï¸ æ®µè½ç´¢å¼• %ld è¶…å‡ºèŒƒå›´", (long)index);
        return;
    }
    
    RecordingSegment *segment = self.recordingSegmentsInternal[index];
    NSLog(@"ğŸ—‘ï¸ åˆ é™¤æ®µè½ %ld: %@", (long)index, segment);
    
    [self.recordingSegmentsInternal removeObjectAtIndex:index];
    
    // é€šçŸ¥ä»£ç†
    [self notifySegmentsUpdate];
}

// ğŸ†• æ¸…ç©ºæ‰€æœ‰æ®µè½
- (void)clearAllSegments {
    NSLog(@"ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰æ®µè½ï¼ˆå…± %lu ä¸ªï¼‰", (unsigned long)self.recordingSegmentsInternal.count);
    [self.recordingSegmentsInternal removeAllObjects];
    self.currentSegment = nil;
    
    // é€šçŸ¥ä»£ç†
    [self notifySegmentsUpdate];
}

// ğŸ†• è·å–å·²å½•åˆ¶çš„æ€»æ—¶é•¿
- (NSTimeInterval)getTotalRecordedDuration {
    NSTimeInterval total = 0.0;
    for (RecordingSegment *segment in self.recordingSegmentsInternal) {
        if (segment.isRecorded) {
            total += segment.duration;
        }
    }
    return total;
}

// é€šçŸ¥ä»£ç†æ®µè½å·²æ›´æ–°
- (void)notifySegmentsUpdate {
    if ([self.delegate respondsToSelector:@selector(audioEngineDidUpdateRecordingSegments:)]) {
        dispatch_async(dispatch_get_main_queue(), ^{
            [self.delegate audioEngineDidUpdateRecordingSegments:[self.recordingSegments copy]];
        });
    }
}

- (NSString *)getRecordingFilePath {
    return self.recordingFilePath;
}

#pragma mark - éŸ³é¢‘åˆæˆ

#pragma mark - ğŸ†• é¢„è§ˆå’Œè¯•å¬

// ğŸ†• é¢„è§ˆåˆæˆï¼ˆä¸ä¿å­˜æ–‡ä»¶ï¼Œè¿”å›éŸ³é¢‘æ•°æ®ï¼‰
- (NSData *)previewSynthesizedAudio {
    // ğŸ”§ æ£€æŸ¥ç¼“å­˜
    if (self.previewAudioData) {
        NSLog(@"âœ… ä½¿ç”¨ç¼“å­˜çš„é¢„è§ˆæ•°æ®ï¼ˆå‚æ•°æœªæ”¹å˜ï¼‰");
        return self.previewAudioData;
    }
    
    // ğŸ”§ ä½¿ç”¨å½“å‰å®é™…å‚æ•°é‡æ–°ç”Ÿæˆ
    // BGMéŸ³é‡ä»audioPlayerè¯»å–ï¼ˆç”¨æˆ·å¯èƒ½å·²è°ƒæ•´ï¼‰
    float currentBGMVolume = self.audioPlayer ? self.audioPlayer.volume : self.bgmVolume;
    
    NSLog(@"ğŸ“Š å½“å‰é¢„è§ˆå‚æ•°:");
    NSLog(@"   BGMéŸ³é‡: %.0f%% (audioPlayer.volume)", currentBGMVolume * 100);
    NSLog(@"   éº¦å…‹é£éŸ³é‡: %.0f%%", self.microphoneVolume * 100);
    NSLog(@"   éŸ³æ•ˆ: %@", [VoiceEffectProcessor nameForEffectType:self.voiceEffectProcessor.effectType]);
    
    return [self previewSynthesizedAudioWithBGMVolume:currentBGMVolume 
                                            micVolume:self.microphoneVolume 
                                               effect:self.voiceEffectProcessor.effectType];
}

// ğŸ†• ä½¿ç”¨æŒ‡å®šå‚æ•°é¢„è§ˆï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰
- (NSData *)previewSynthesizedAudioWithBGMVolume:(float)bgmVolume 
                                       micVolume:(float)micVolume 
                                          effect:(VoiceEffectType)effectType {
    if (self.recordingSegmentsInternal.count == 0) {
        NSLog(@"âš ï¸ æ²¡æœ‰å½•éŸ³æ®µè½å¯é¢„è§ˆ");
        return nil;
    }
    
    NSLog(@"ğŸ¬ å¼€å§‹ç”Ÿæˆé¢„è§ˆéŸ³é¢‘ï¼ˆ%lu ä¸ªæ®µè½ï¼‰...", (unsigned long)self.recordingSegmentsInternal.count);
    NSLog(@"   å‚æ•°: BGM=%.0f%%, éº¦å…‹é£=%.0f%%, éŸ³æ•ˆ=%@", 
          bgmVolume * 100, micVolume * 100, 
          [VoiceEffectProcessor nameForEffectType:effectType]);
    
    // åŠ¨æ€åˆæˆï¼ˆä½¿ç”¨æ–°å‚æ•°ï¼‰
    NSData *synthesizedData = [self synthesizeAudioDataWithBGMVolume:bgmVolume 
                                                           micVolume:micVolume 
                                                              effect:effectType];
    
    // ç¼“å­˜é¢„è§ˆæ•°æ®
    self.previewAudioData = synthesizedData;
    
    NSLog(@"âœ… é¢„è§ˆéŸ³é¢‘ç”Ÿæˆå®Œæˆ: %.2fMB", synthesizedData.length / (1024.0 * 1024.0));
    
    return synthesizedData;
}

// ğŸ†• æ¸…é™¤é¢„è§ˆç¼“å­˜
- (void)invalidatePreviewCache {
    self.previewAudioData = nil;
    NSLog(@"ğŸ—‘ï¸ é¢„è§ˆç¼“å­˜å·²æ¸…é™¤");
}

// ğŸ†• æ’­æ”¾é¢„è§ˆéŸ³é¢‘
- (void)playPreview:(void (^)(NSError *error))completion {
    NSLog(@"ğŸ§ å¼€å§‹æ’­æ”¾é¢„è§ˆ...");
    
    // åœæ­¢å½“å‰é¢„è§ˆ
    [self stopPreview];
    
    // æš‚åœBGMæ’­æ”¾
    if (self.isPlaying) {
        [self pause];
        NSLog(@"â¸ï¸ BGMå·²æš‚åœ");
    }
    
    // åœæ­¢AUGraphï¼ˆé¿å…å†²çªï¼‰
    Boolean isRunning = false;
    AUGraphIsRunning(self.auGraph, &isRunning);
    if (isRunning) {
        CheckError(AUGraphStop(self.auGraph), "AUGraphStop for preview");
        NSLog(@"ğŸ›‘ AUGraphå·²åœæ­¢");
    }
    
    // ç”Ÿæˆé¢„è§ˆéŸ³é¢‘
    NSData *audioData = [self previewSynthesizedAudio];
    if (!audioData) {
        NSError *error = [NSError errorWithDomain:@"KaraokeAudioEngine" 
                                             code:-1 
                                         userInfo:@{NSLocalizedDescriptionKey: @"æ— æ³•ç”Ÿæˆé¢„è§ˆéŸ³é¢‘"}];
        if (completion) completion(error);
        return;
    }
    
    // ä¿å­˜é¢„è§ˆå®Œæˆå›è°ƒ
    self.previewCompletion = completion;
    
    // å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼ˆAVAudioPlayeréœ€è¦æ–‡ä»¶ï¼‰
    NSString *tempPath = [NSTemporaryDirectory() stringByAppendingPathComponent:@"preview_temp.pcm"];
    [audioData writeToFile:tempPath atomically:YES];
    
    // åˆ›å»ºæ’­æ”¾å™¨ï¼ˆéœ€è¦å…ˆè½¬æ¢ä¸ºå…¼å®¹æ ¼å¼ï¼‰
    NSError *error = nil;
    
    // è·å–ç³»ç»Ÿé‡‡æ ·ç‡
    AVAudioSession *audioSession = [AVAudioSession sharedInstance];
    double sampleRate = audioSession.sampleRate;
    
    // å°†PCMæ•°æ®åŒ…è£…ä¸ºCAFæ ¼å¼ï¼ˆAVAudioPlayerå¯ä»¥æ’­æ”¾ï¼‰
    NSString *cafPath = [self convertPCMToCAF:audioData sampleRate:sampleRate];
    if (!cafPath) {
        error = [NSError errorWithDomain:@"KaraokeAudioEngine" 
                                    code:-2 
                                userInfo:@{NSLocalizedDescriptionKey: @"éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥"}];
        if (completion) completion(error);
        return;
    }
    
    NSURL *url = [NSURL fileURLWithPath:cafPath];
    self.previewPlayer = [[AVAudioPlayer alloc] initWithContentsOfURL:url error:&error];
    
    if (error) {
        NSLog(@"âŒ åˆ›å»ºé¢„è§ˆæ’­æ”¾å™¨å¤±è´¥: %@", error);
        if (completion) completion(error);
        return;
    }
    
    self.previewPlayer.delegate = self;
    [self.previewPlayer prepareToPlay];
    
    BOOL success = [self.previewPlayer play];
    if (success) {
        NSLog(@"âœ… é¢„è§ˆæ’­æ”¾å¼€å§‹ï¼ˆæ—¶é•¿: %.2fç§’ï¼‰", self.previewPlayer.duration);
    } else {
        error = [NSError errorWithDomain:@"KaraokeAudioEngine" 
                                    code:-3 
                                userInfo:@{NSLocalizedDescriptionKey: @"æ’­æ”¾å™¨å¯åŠ¨å¤±è´¥"}];
        if (completion) completion(error);
    }
}

// ğŸ†• åœæ­¢é¢„è§ˆæ’­æ”¾
- (void)stopPreview {
    if (self.previewPlayer && self.previewPlayer.isPlaying) {
        [self.previewPlayer stop];
        NSLog(@"ğŸ›‘ é¢„è§ˆæ’­æ”¾å·²åœæ­¢");
    }
    self.previewPlayer = nil;
    self.previewCompletion = nil;
}

// ğŸ†• æ˜¯å¦æ­£åœ¨æ’­æ”¾é¢„è§ˆ
- (BOOL)isPlayingPreview {
    return self.previewPlayer && self.previewPlayer.isPlaying;
}

// ğŸ†• å®æ—¶æ›´æ–°é¢„è§ˆå‚æ•°ï¼ˆæ’­æ”¾ä¸­ç”Ÿæ•ˆï¼‰
- (void)updatePreviewParametersIfPlaying {
    if (![self isPlayingPreview]) {
        NSLog(@"âš ï¸ å½“å‰æœªæ’­æ”¾é¢„è§ˆï¼Œè·³è¿‡å‚æ•°æ›´æ–°");
        return;
    }
    
    NSLog(@"ğŸ”„ æ£€æµ‹åˆ°æ’­æ”¾ä¸­å‚æ•°æ”¹å˜ï¼Œå‡†å¤‡å®æ—¶æ›´æ–°...");
    
    // 1. è®°ä½å½“å‰æ’­æ”¾ä½ç½®
    NSTimeInterval currentTime = self.previewPlayer.currentTime;
    NSLog(@"ğŸ“ å½“å‰æ’­æ”¾ä½ç½®: %.2fç§’", currentTime);
    
    // 2. æ¸…é™¤æ—§ç¼“å­˜
    [self invalidatePreviewCache];
    
    // 3. é‡æ–°ç”ŸæˆéŸ³é¢‘ï¼ˆä½¿ç”¨æ–°å‚æ•°ï¼‰
    NSLog(@"ğŸ¬ ä½¿ç”¨æ–°å‚æ•°é‡æ–°ç”ŸæˆéŸ³é¢‘...");
    NSData *newAudioData = [self previewSynthesizedAudio];
    if (!newAudioData) {
        NSLog(@"âŒ é‡æ–°ç”Ÿæˆå¤±è´¥");
        return;
    }
    
    // 4. è½¬æ¢ä¸ºCAFæ ¼å¼
    AVAudioSession *audioSession = [AVAudioSession sharedInstance];
    double sampleRate = audioSession.sampleRate;
    NSString *newCafPath = [self convertPCMToCAF:newAudioData sampleRate:sampleRate];
    if (!newCafPath) {
        NSLog(@"âŒ æ ¼å¼è½¬æ¢å¤±è´¥");
        return;
    }
    
    // 5. åœæ­¢æ—§æ’­æ”¾å™¨
    [self.previewPlayer stop];
    
    // 6. åˆ›å»ºæ–°æ’­æ”¾å™¨
    NSError *error = nil;
    NSURL *cafURL = [NSURL fileURLWithPath:newCafPath];
    AVAudioPlayer *newPlayer = [[AVAudioPlayer alloc] initWithContentsOfURL:cafURL error:&error];
    if (error || !newPlayer) {
        NSLog(@"âŒ åˆ›å»ºæ–°æ’­æ”¾å™¨å¤±è´¥: %@", error);
        return;
    }
    
    newPlayer.delegate = self;
    [newPlayer prepareToPlay];
    
    // 7. è·³è½¬åˆ°ä¹‹å‰çš„æ’­æ”¾ä½ç½®
    if (currentTime < newPlayer.duration) {
        newPlayer.currentTime = currentTime;
        NSLog(@"ğŸ“ æ¢å¤æ’­æ”¾ä½ç½®: %.2fç§’", currentTime);
    } else {
        NSLog(@"âš ï¸ åŸæ’­æ”¾ä½ç½®è¶…å‡ºæ–°éŸ³é¢‘é•¿åº¦ï¼Œä»å¤´æ’­æ”¾");
        newPlayer.currentTime = 0;
    }
    
    // 8. æ›¿æ¢æ’­æ”¾å™¨å¹¶ç»§ç»­æ’­æ”¾
    self.previewPlayer = newPlayer;
    [self.previewPlayer play];
    
    NSLog(@"âœ… å‚æ•°å®æ—¶æ›´æ–°å®Œæˆï¼Œç»§ç»­æ’­æ”¾");
}

// ğŸ†• è·å–é¢„è§ˆæ’­æ”¾å½“å‰æ—¶é—´
- (NSTimeInterval)currentPreviewTime {
    if (self.previewPlayer) {
        return self.previewPlayer.currentTime;
    }
    return 0;
}

// ğŸ†• è·å–é¢„è§ˆéŸ³é¢‘æ€»æ—¶é•¿
- (NSTimeInterval)previewDuration {
    if (self.previewPlayer) {
        return self.previewPlayer.duration;
    }
    return 0;
}

// ğŸ†• ä¿å­˜é¢„è§ˆåˆ°æ–‡ä»¶
- (void)savePreviewToFile:(void (^)(NSString *filePath, NSError *error))completion {
    NSLog(@"ğŸ’¾ ä¿å­˜é¢„è§ˆåˆ°æ–‡ä»¶...");
    
    NSData *audioData = self.previewAudioData;
    if (!audioData) {
        audioData = [self previewSynthesizedAudio];
    }
    
    if (!audioData) {
        NSError *error = [NSError errorWithDomain:@"KaraokeAudioEngine" 
                                             code:-1 
                                         userInfo:@{NSLocalizedDescriptionKey: @"æ— æ³•ç”ŸæˆéŸ³é¢‘æ•°æ®"}];
        if (completion) completion(nil, error);
        return;
    }
    
    // ç”Ÿæˆæ–‡ä»¶è·¯å¾„
    NSArray *paths = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES);
    NSString *documentsDirectory = [paths objectAtIndex:0];
    NSString *fileName = [NSString stringWithFormat:@"karaoke_final_%ld.pcm", (long)[[NSDate date] timeIntervalSince1970]];
    NSString *filePath = [documentsDirectory stringByAppendingPathComponent:fileName];
    
    // ä¿å­˜æ–‡ä»¶
    BOOL success = [audioData writeToFile:filePath atomically:YES];
    
    if (success) {
        self.recordingFilePath = filePath;
        NSLog(@"âœ… æ–‡ä»¶ä¿å­˜æˆåŠŸ: %@", filePath);
        if (completion) completion(filePath, nil);
    } else {
        NSError *error = [NSError errorWithDomain:@"KaraokeAudioEngine" 
                                             code:-2 
                                         userInfo:@{NSLocalizedDescriptionKey: @"æ–‡ä»¶å†™å…¥å¤±è´¥"}];
        NSLog(@"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥");
        if (completion) completion(nil, error);
    }
}

// ğŸ†• åˆæˆéŸ³é¢‘æ•°æ®ï¼ˆå¸¦å‚æ•°ï¼Œæ”¯æŒåŠ¨æ€è°ƒæ•´ï¼‰
- (NSData *)synthesizeAudioDataWithBGMVolume:(float)bgmVolume 
                                   micVolume:(float)micVolume 
                                      effect:(VoiceEffectType)effectType {
    if (self.recordingSegmentsInternal.count == 0) {
        NSLog(@"âš ï¸ æ²¡æœ‰å½•éŸ³æ®µè½å¯åˆæˆ");
        return nil;
    }
    
    NSLog(@"ğŸ¬ å¼€å§‹åˆæˆ %lu ä¸ªå½•éŸ³æ®µè½...", (unsigned long)self.recordingSegmentsInternal.count);
    
    // 1. æŒ‰æ—¶é—´æ’åºæ®µè½
    NSArray *sortedSegments = [self.recordingSegmentsInternal sortedArrayUsingComparator:^NSComparisonResult(RecordingSegment *seg1, RecordingSegment *seg2) {
        if (seg1.startTime < seg2.startTime) return NSOrderedAscending;
        if (seg1.startTime > seg2.startTime) return NSOrderedDescending;
        return NSOrderedSame;
    }];
    
    // 2. åˆ›å»ºæœ€ç»ˆè¾“å‡ºç¼“å†²åŒº
    NSMutableData *finalAudio = [NSMutableData data];
    
    // 3. è·å–ç³»ç»Ÿé‡‡æ ·ç‡
    AVAudioSession *audioSession = [AVAudioSession sharedInstance];
    double systemSampleRate = audioSession.sampleRate;
    
    // 4. åˆ›å»ºéŸ³æ•ˆå¤„ç†å™¨ï¼ˆå¦‚æœéœ€è¦é‡æ–°åº”ç”¨éŸ³æ•ˆï¼‰
    VoiceEffectProcessor *previewEffectProcessor = nil;
    if (effectType != VoiceEffectTypeNone) {
        previewEffectProcessor = [[VoiceEffectProcessor alloc] initWithSampleRate:systemSampleRate];
        [previewEffectProcessor setPresetEffect:effectType];
        NSLog(@"ğŸµ é¢„è§ˆå°†åº”ç”¨éŸ³æ•ˆ: %@", [VoiceEffectProcessor nameForEffectType:effectType]);
    }
    
    // 5. é€æ®µå¤„ç†
    NSTimeInterval currentTime = 0.0;
    NSTimeInterval lastSegmentEndTime = 0.0;
    
    for (RecordingSegment *segment in sortedSegments) {
        
        // å¡«å……æ®µè½é—´çš„BGMç©ºç™½
        if (segment.startTime > currentTime) {
            NSTimeInterval gapDuration = segment.startTime - currentTime;
            NSLog(@"ğŸµ å¡«å……çº¯BGM: %.2f~%.2fs (%.2fç§’)", currentTime, segment.startTime, gapDuration);
            
            NSData *bgmGap = [self extractBGMFromTime:currentTime 
                                            duration:gapDuration 
                                          sampleRate:systemSampleRate 
                                              volume:bgmVolume];
            if (bgmGap) {
                [finalAudio appendData:bgmGap];
            }
        }
        
        // å¤„ç†å½•éŸ³æ®µè½
        if (segment.isRecorded && segment.vocalData.length > 0) {
            NSLog(@"ğŸ¤ å¤„ç†å½•åˆ¶æ®µè½: %.2f~%.2fs", segment.startTime, segment.startTime + segment.duration);
            
            // ğŸ†• åŠ¨æ€åˆæˆï¼šäººå£° + BGMï¼ˆä½¿ç”¨æ–°å‚æ•°ï¼‰
            NSData *mixedSegment = [self remixSegment:segment 
                                          bgmVolume:bgmVolume 
                                          micVolume:micVolume 
                                    effectProcessor:previewEffectProcessor 
                                         sampleRate:systemSampleRate];
            
            if (mixedSegment) {
                [finalAudio appendData:mixedSegment];
            }
        } else {
            // çº¯BGMæ®µè½
            NSLog(@"ğŸµ æ·»åŠ çº¯BGMæ®µè½: %.2f~%.2fs", segment.startTime, segment.startTime + segment.duration);
            NSData *bgmSegment = [self extractBGMFromTime:segment.startTime 
                                                duration:segment.duration 
                                              sampleRate:systemSampleRate 
                                                  volume:bgmVolume];
            if (bgmSegment) {
                [finalAudio appendData:bgmSegment];
            }
        }
        
        currentTime = segment.startTime + segment.duration;
        lastSegmentEndTime = currentTime;
    }
    
    NSLog(@"ğŸ“Š åˆæˆç»Ÿè®¡:");
    NSLog(@"   æœ€åæ®µè½ç»“æŸæ—¶é—´: %.2fç§’", lastSegmentEndTime);
    NSLog(@"   BGMæ€»æ—¶é•¿: %.2fç§’", self.audioPlayer.duration);
    NSLog(@"   åˆæˆç­–ç•¥: åªä¿ç•™å·²å½•åˆ¶éƒ¨åˆ†ï¼ˆ%.2fç§’ï¼‰", lastSegmentEndTime);
    
    NSTimeInterval totalDuration = finalAudio.length / sizeof(SInt16) / systemSampleRate;
    NSLog(@"âœ… éŸ³é¢‘æ•°æ®åˆæˆå®Œæˆ:");
    NSLog(@"   æ€»å¤§å°: %.2fMB", finalAudio.length / (1024.0 * 1024.0));
    NSLog(@"   æ€»æ—¶é•¿: %.2fç§’", totalDuration);
    NSLog(@"   é‡‡æ ·ç‡: %.0fHz", systemSampleRate);
    
    return [finalAudio copy];
}

// ğŸ†• å°†PCMè½¬æ¢ä¸ºCAFæ ¼å¼ï¼ˆAVAudioPlayerå¯æ’­æ”¾ï¼‰
- (NSString *)convertPCMToCAF:(NSData *)pcmData sampleRate:(double)sampleRate {
    NSString *cafPath = [NSTemporaryDirectory() stringByAppendingPathComponent:@"preview.caf"];
    
    // è®¾ç½®éŸ³é¢‘æ ¼å¼
    AudioStreamBasicDescription asbd = {0};
    asbd.mSampleRate = sampleRate;
    asbd.mFormatID = kAudioFormatLinearPCM;
    asbd.mFormatFlags = kLinearPCMFormatFlagIsSignedInteger | kLinearPCMFormatFlagIsPacked;
    asbd.mBitsPerChannel = 16;
    asbd.mChannelsPerFrame = 1;
    asbd.mBytesPerFrame = 2;
    asbd.mFramesPerPacket = 1;
    asbd.mBytesPerPacket = 2;
    
    // åˆ›å»ºéŸ³é¢‘æ–‡ä»¶
    CFURLRef fileURL = (__bridge CFURLRef)[NSURL fileURLWithPath:cafPath];
    AudioFileID audioFile;
    OSStatus status = AudioFileCreateWithURL(fileURL,
                                            kAudioFileCAFType,
                                            &asbd,
                                            kAudioFileFlags_EraseFile,
                                            &audioFile);
    
    if (status != noErr) {
        NSLog(@"âŒ åˆ›å»ºCAFæ–‡ä»¶å¤±è´¥: %d", (int)status);
        return nil;
    }
    
    // å†™å…¥PCMæ•°æ®
    UInt32 bytesToWrite = (UInt32)pcmData.length;
    status = AudioFileWriteBytes(audioFile,
                                false,
                                0,
                                &bytesToWrite,
                                pcmData.bytes);
    
    AudioFileClose(audioFile);
    
    if (status != noErr) {
        NSLog(@"âŒ å†™å…¥CAFæ•°æ®å¤±è´¥: %d", (int)status);
        return nil;
    }
    
    NSLog(@"âœ… PCMè½¬CAFæˆåŠŸ: %@", cafPath);
    return cafPath;
}

// å‘åå…¼å®¹ï¼šä½¿ç”¨å½“å‰å‚æ•°åˆæˆ
- (NSData *)synthesizeAudioData {
    return [self synthesizeAudioDataWithBGMVolume:self.bgmVolume 
                                        micVolume:self.microphoneVolume 
                                           effect:self.voiceEffectProcessor.effectType];
}

// ğŸ†• åˆæˆæœ€ç»ˆå½•éŸ³æ–‡ä»¶ï¼ˆå°†æ‰€æœ‰æ®µè½æ‹¼æ¥ï¼Œå¹¶å¡«å……BGMåˆ°è·³è¿‡çš„éƒ¨åˆ†ï¼‰
- (void)synthesizeFinalRecording {
    NSLog(@"ğŸ’¾ å¼€å§‹ä¿å­˜æœ€ç»ˆæ–‡ä»¶...");
    
    // ä½¿ç”¨å…±äº«çš„åˆæˆé€»è¾‘
    NSData *finalAudio = [self synthesizeAudioData];
    
    if (!finalAudio) {
        NSLog(@"âŒ åˆæˆå¤±è´¥");
        return;
    }
    
    // ä¿å­˜åˆ°æ–‡ä»¶
    NSArray *paths = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES);
    NSString *documentsDirectory = [paths objectAtIndex:0];
    NSString *fileName = [NSString stringWithFormat:@"karaoke_final_%ld.pcm", (long)[[NSDate date] timeIntervalSince1970]];
    self.recordingFilePath = [documentsDirectory stringByAppendingPathComponent:fileName];
    
    BOOL success = [finalAudio writeToFile:self.recordingFilePath atomically:YES];
    
    if (success) {
        AVAudioSession *audioSession = [AVAudioSession sharedInstance];
        double systemSampleRate = audioSession.sampleRate;
        NSTimeInterval totalDuration = finalAudio.length / sizeof(SInt16) / systemSampleRate;
        NSLog(@"âœ… æœ€ç»ˆæ–‡ä»¶ä¿å­˜æˆåŠŸ:");
        NSLog(@"   æ–‡ä»¶è·¯å¾„: %@", self.recordingFilePath);
        NSLog(@"   æ–‡ä»¶å¤§å°: %.2fMB", finalAudio.length / (1024.0 * 1024.0));
        NSLog(@"   æ–‡ä»¶æ—¶é•¿: %.2fç§’", totalDuration);
    } else {
        NSLog(@"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥: %@", self.recordingFilePath);
    }
}

// ğŸ†• é‡æ–°æ··åˆæ®µè½ï¼ˆä½¿ç”¨æ–°å‚æ•°ï¼‰
- (NSData *)remixSegment:(RecordingSegment *)segment 
               bgmVolume:(float)bgmVolume 
               micVolume:(float)micVolume 
         effectProcessor:(VoiceEffectProcessor *)effectProcessor 
              sampleRate:(double)sampleRate {
    
    if (!segment.vocalData || segment.vocalData.length == 0) {
        NSLog(@"âš ï¸ æ®µè½æ²¡æœ‰äººå£°æ•°æ®");
        return nil;
    }
    
    // 1. è·å–äººå£°æ•°æ®
    const SInt16 *vocalSamples = (const SInt16 *)segment.vocalData.bytes;
    NSUInteger vocalSampleCount = segment.vocalData.length / sizeof(SInt16);
    
    // 2. åˆ›å»ºè¾“å‡ºç¼“å†²åŒº
    NSMutableData *outputData = [NSMutableData dataWithLength:segment.vocalData.length];
    SInt16 *outputSamples = (SInt16 *)outputData.mutableBytes;
    
    // 3. å¤åˆ¶å¹¶è°ƒæ•´äººå£°éŸ³é‡
    for (NSUInteger i = 0; i < vocalSampleCount; i++) {
        int32_t sample = (int32_t)(vocalSamples[i] * micVolume);
        
        // é˜²æ­¢æº¢å‡º
        if (sample > 32767) sample = 32767;
        if (sample < -32768) sample = -32768;
        
        outputSamples[i] = (SInt16)sample;
    }
    
    // 4. ğŸ”§ Bugä¿®å¤ï¼šåº”ç”¨éŸ³æ•ˆï¼ˆvocalDataæ˜¯åŸå§‹æ•°æ®ï¼Œæœªåº”ç”¨éŸ³æ•ˆï¼‰
    if (effectProcessor) {
        if (effectProcessor.effectType != segment.appliedEffect) {
            NSLog(@"   ğŸµ é¢„è§ˆå°†åº”ç”¨éŸ³æ•ˆ: %@ï¼ˆå½•åˆ¶æ—¶: %@ï¼‰", 
                  [VoiceEffectProcessor nameForEffectType:effectProcessor.effectType],
                  [VoiceEffectProcessor nameForEffectType:segment.appliedEffect]);
        } else {
            NSLog(@"   ğŸµ é¢„è§ˆå°†åº”ç”¨éŸ³æ•ˆ: %@ï¼ˆä¸å½•åˆ¶æ—¶ç›¸åŒï¼‰", 
                  [VoiceEffectProcessor nameForEffectType:effectProcessor.effectType]);
        }
        [effectProcessor processAudioBuffer:outputSamples sampleCount:(UInt32)vocalSampleCount];
    } else {
        NSLog(@"   âš ï¸ æ— éŸ³æ•ˆå¤„ç†å™¨");
    }
    
    // 5. æ··åˆBGM
    NSData *bgmData = [self extractBGMFromTime:segment.startTime 
                                      duration:segment.duration 
                                    sampleRate:sampleRate 
                                        volume:bgmVolume];
    
    if (bgmData && bgmData.length == outputData.length) {
        const SInt16 *bgmSamples = (const SInt16 *)bgmData.bytes;
        
        for (NSUInteger i = 0; i < vocalSampleCount; i++) {
            int32_t vocalSample = outputSamples[i];
            int32_t bgmSample = bgmSamples[i];
            int32_t mixed = vocalSample + bgmSample;
            
            // è½¯å‰Šæ³¢
            if (mixed > 32767 || mixed < -32768) {
                float compressionRatio = 29490.0f / fabs(mixed);
                mixed = (int32_t)(mixed * compressionRatio);
            }
            
            outputSamples[i] = (SInt16)mixed;
        }
    }
    
    return outputData;
}

// ğŸ†• ä»BGMä¸­æå–æŒ‡å®šæ—¶é—´æ®µçš„æ•°æ®ï¼ˆå¸¦éŸ³é‡å‚æ•°ï¼‰
- (NSData *)extractBGMFromTime:(NSTimeInterval)startTime 
                      duration:(NSTimeInterval)duration 
                    sampleRate:(double)sampleRate 
                        volume:(float)volume {
    if (!self.bgmPCMData || self.bgmPCMDataLength == 0) {
        NSLog(@"âš ï¸ BGMæ•°æ®ä¸ºç©º");
        return nil;
    }
    
    // è®¡ç®—æ ·æœ¬èŒƒå›´
    NSUInteger startSample = (NSUInteger)(startTime * sampleRate);
    NSUInteger sampleCount = (NSUInteger)(duration * sampleRate);
    
    // è¾¹ç•Œæ£€æŸ¥
    if (startSample >= self.bgmPCMDataLength) {
        NSLog(@"âš ï¸ BGMèµ·å§‹ä½ç½®è¶…å‡ºèŒƒå›´");
        return nil;
    }
    
    // è°ƒæ•´æ ·æœ¬æ•°é‡
    if (startSample + sampleCount > self.bgmPCMDataLength) {
        sampleCount = self.bgmPCMDataLength - startSample;
    }
    
    // æå–å¹¶åº”ç”¨éŸ³é‡
    const SInt16 *bgmSamples = (const SInt16 *)self.bgmPCMData.bytes;
    NSMutableData *extractedData = [NSMutableData dataWithLength:sampleCount * sizeof(SInt16)];
    SInt16 *outputSamples = (SInt16 *)extractedData.mutableBytes;
    
    for (NSUInteger i = 0; i < sampleCount; i++) {
        int32_t sample = (int32_t)(bgmSamples[startSample + i] * volume);
        
        // é˜²æ­¢æº¢å‡º
        if (sample > 32767) sample = 32767;
        if (sample < -32768) sample = -32768;
        
        outputSamples[i] = (SInt16)sample;
    }
    
    return extractedData;
}

// ğŸ†• ä»BGMä¸­æå–æŒ‡å®šæ—¶é—´æ®µçš„æ•°æ®ï¼ˆå‘åå…¼å®¹ï¼Œä½¿ç”¨å½“å‰BGMéŸ³é‡ï¼‰
- (NSData *)extractBGMFromTime:(NSTimeInterval)startTime duration:(NSTimeInterval)duration sampleRate:(double)sampleRate {
    return [self extractBGMFromTime:startTime duration:duration sampleRate:sampleRate volume:self.bgmVolume];
}


#pragma mark - éŸ³é¢‘æ’­æ”¾

- (void)loadAudioFile:(NSString *)filePath {
    NSError *error;
    NSURL *fileURL = [NSURL fileURLWithPath:filePath];
    
    // 1. åŠ è½½AVAudioPlayerï¼ˆç”¨äºæ˜¾ç¤ºè¿›åº¦å’Œæ§åˆ¶ï¼‰
    self.audioPlayer = [[AVAudioPlayer alloc] initWithContentsOfURL:fileURL error:&error];
    if (error) {
        NSLog(@"âŒ åŠ è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: %@", error.localizedDescription);
        return;
    }
    self.audioPlayer.delegate = self;  // è®¾ç½®ä»£ç†ä»¥ç›‘å¬æ’­æ”¾å®Œæˆ
    [self.audioPlayer prepareToPlay];
    
    // ğŸ”§ åº”ç”¨å½“å‰çš„ BGM éŸ³é‡è®¾ç½®
    self.audioPlayer.volume = self.bgmVolume;
    
    // ğŸ”§ å¯ç”¨å˜é€Ÿæ’­æ”¾ï¼ˆè™½ç„¶æˆ‘ä»¬ç”¨rate=1.0ï¼Œä½†éœ€è¦å¯ç”¨æ‰èƒ½è®¾ç½®ï¼‰
    self.audioPlayer.enableRate = YES;
    self.audioPlayer.rate = 1.0;
    
    NSLog(@"ğŸµ AVAudioPlayer é…ç½®:");
    NSLog(@"   éŸ³é‡: %.0f%%", self.bgmVolume * 100);
    NSLog(@"   æ—¶é•¿: %.2fç§’", self.audioPlayer.duration);
    NSLog(@"   å£°é“æ•°: %lu", (unsigned long)self.audioPlayer.numberOfChannels);
    NSLog(@"   æ’­æ”¾é€Ÿç‡: %.2f", self.audioPlayer.rate);
    
    // 2. å°†æ•´ä¸ªBGMæ–‡ä»¶è½¬æ¢ä¸ºPCMæ ¼å¼å¹¶åŠ è½½åˆ°å†…å­˜
    NSLog(@"ğŸ”„ å¼€å§‹è½¬æ¢BGMæ–‡ä»¶ä¸ºPCM...");
    NSData *pcmData = [self convertAudioFileToPCM:filePath];
    
    if (pcmData) {
        // åŸå­èµ‹å€¼ï¼Œä¸éœ€è¦é”
        self.bgmPCMData = pcmData;
        NSUInteger originalLength = pcmData.length / sizeof(int16_t);
        
        // è·å–ç³»ç»Ÿé‡‡æ ·ç‡ç”¨äºè®¡ç®—æ—¶é•¿
        AVAudioSession *audioSession = [AVAudioSession sharedInstance];
        double systemSampleRate = audioSession.sampleRate;
        
        NSLog(@"âœ… BGMæ–‡ä»¶è½¬æ¢æˆåŠŸ");
        NSLog(@"   æ–‡ä»¶å¤§å°: %.2f MB", self.bgmPCMData.length / (1024.0 * 1024.0));
        NSLog(@"   æ ·æœ¬æ•°: %lu", (unsigned long)originalLength);
        NSLog(@"   è½¬æ¢åæ—¶é•¿: %.2fç§’", originalLength / systemSampleRate);
        NSLog(@"   AVAudioPlayer æ—¶é•¿: %.2fç§’", self.audioPlayer.duration);
        
        // ğŸ†• ç›´æ¥ä½¿ç”¨è½¬æ¢åçš„ç²¾ç¡®é•¿åº¦ï¼ˆAVAudioFileå·²ç»æä¾›äº†æ­£ç¡®çš„å¸§æ•°ï¼‰
        // ä¸å†éœ€è¦æ ¹æ®AVAudioPlayeræ ¡å‡†ï¼Œå› ä¸ºAVAudioFileçš„é•¿åº¦æ˜¯ç²¾ç¡®çš„
        self.bgmPCMDataLength = originalLength;
        self.bgmReadPosition = 0;
        
        NSLog(@"ğŸ“Š æœ€ç»ˆ BGM å‚æ•°:");
        NSLog(@"   æ ·æœ¬æ•°: %lu", (unsigned long)self.bgmPCMDataLength);
        NSLog(@"   ç³»ç»Ÿé‡‡æ ·ç‡: %.0f Hz", systemSampleRate);
        NSLog(@"   ç²¾ç¡®æ—¶é•¿: %.2fç§’", self.bgmPCMDataLength / systemSampleRate);
    } else {
        NSLog(@"âŒ BGMæ–‡ä»¶è½¬æ¢å¤±è´¥");
    }
    
    NSLog(@"âœ… éŸ³é¢‘æ–‡ä»¶åŠ è½½æˆåŠŸ: %@", filePath);
}

// å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºPCMæ ¼å¼ (ç³»ç»Ÿé‡‡æ ·ç‡, å•å£°é“, 16bit)
// ğŸ”§ ä¼˜åŒ–ï¼šä½¿ç”¨ç³»ç»Ÿå®é™…é‡‡æ ·ç‡ï¼Œé¿å…é€Ÿåº¦ä¸åŒ¹é…
- (NSData *)convertAudioFileToPCM:(NSString *)audioFilePath {
    NSURL *audioURL = [NSURL fileURLWithPath:audioFilePath];
    
    // æ‰“å¼€éŸ³é¢‘æ–‡ä»¶
    NSError *error;
    AVAudioFile *audioFile = [[AVAudioFile alloc] initForReading:audioURL error:&error];
    if (error) {
        NSLog(@"âŒ æ— æ³•æ‰“å¼€éŸ³é¢‘æ–‡ä»¶: %@", error.localizedDescription);
        return nil;
    }
    
    NSLog(@"ğŸ“Š éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯:");
    NSLog(@"   æ ¼å¼: %@", audioFile.processingFormat);
    NSLog(@"   é‡‡æ ·ç‡: %.0f Hz", audioFile.processingFormat.sampleRate);
    NSLog(@"   å£°é“æ•°: %u", audioFile.processingFormat.channelCount);
    NSLog(@"   å¸§æ•°: %lld", audioFile.length);
    NSLog(@"   ç²¾ç¡®æ—¶é•¿: %.2fç§’", (double)audioFile.length / audioFile.processingFormat.sampleRate);
    
    // ğŸ”§ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç³»ç»Ÿå®é™…é‡‡æ ·ç‡è€Œä¸æ˜¯å›ºå®š44100 Hz
    AVAudioSession *audioSession = [AVAudioSession sharedInstance];
    double systemSampleRate = audioSession.sampleRate;
    
    NSLog(@"ğŸµ ç³»ç»Ÿå®é™…é‡‡æ ·ç‡: %.0f Hz", systemSampleRate);
    
    // è®¾ç½®PCMæ ¼å¼ (ç³»ç»Ÿé‡‡æ ·ç‡, å•å£°é“, 16bit)
    AVAudioFormat *pcmFormat = [[AVAudioFormat alloc] initWithCommonFormat:AVAudioPCMFormatInt16
                                                                sampleRate:systemSampleRate
                                                                  channels:1
                                                               interleaved:YES];
    
    // å‡†å¤‡è¾“å‡ºæ•°æ®
    NSMutableData *pcmData = [NSMutableData data];
    AVAudioFrameCount frameCapacity = 4096;
    
    // å¦‚æœæ ¼å¼ä¸åŒ¹é…ï¼Œéœ€è¦è½¬æ¢
    if (![audioFile.processingFormat isEqual:pcmFormat]) {
        // åˆ›å»ºè½¬æ¢å™¨
        AVAudioConverter *converter = [[AVAudioConverter alloc] initFromFormat:audioFile.processingFormat
                                                                       toFormat:pcmFormat];
        if (!converter) {
            NSLog(@"âŒ æ— æ³•åˆ›å»ºéŸ³é¢‘è½¬æ¢å™¨");
            return nil;
        }
        
        NSLog(@"ğŸ”„ å¼€å§‹æ ¼å¼è½¬æ¢ (%.0f Hz, %uch -> %.0f Hz, 1ch)...", 
              audioFile.processingFormat.sampleRate, 
              audioFile.processingFormat.channelCount,
              systemSampleRate);
        
        // ğŸ”§ è®¡ç®—é¢„æœŸçš„è¾“å‡ºå¸§æ•°ï¼ˆè€ƒè™‘é‡‡æ ·ç‡è½¬æ¢ï¼‰
        double sampleRateRatio = systemSampleRate / audioFile.processingFormat.sampleRate;
        AVAudioFrameCount expectedOutputFrames = (AVAudioFrameCount)(audioFile.length * sampleRateRatio);
        NSLog(@"   é¢„æœŸè¾“å‡ºå¸§æ•°: %u (è½¬æ¢æ¯”ç‡: %.4f)", expectedOutputFrames, sampleRateRatio);
        
        // è¯»å–å¹¶è½¬æ¢
        AVAudioFrameCount totalOutputFrames = 0;
        
        while (audioFile.framePosition < audioFile.length) {
            AVAudioPCMBuffer *inputBuffer = [[AVAudioPCMBuffer alloc] initWithPCMFormat:audioFile.processingFormat
                                                                           frameCapacity:frameCapacity];
            
            // è¯»å–éŸ³é¢‘æ•°æ®
            [audioFile readIntoBuffer:inputBuffer error:&error];
            if (error || inputBuffer.frameLength == 0) {
                break;
            }
            
            // ğŸ”§ è®¡ç®—è¾“å‡ºç¼“å†²åŒºå¤§å°ï¼ˆè€ƒè™‘é‡‡æ ·ç‡è½¬æ¢ï¼Œé¢„ç•™æ›´å¤šç©ºé—´ï¼‰
            AVAudioFrameCount outputCapacity = (AVAudioFrameCount)(inputBuffer.frameLength * sampleRateRatio * 2.0);
            if (outputCapacity < frameCapacity) {
                outputCapacity = frameCapacity;
            }
            
            // ğŸ”§ å…³é”®ä¿®å¤ï¼šå¯¹äºæ¯ä¸ªè¾“å…¥bufferï¼Œå¯èƒ½éœ€è¦å¤šæ¬¡è½¬æ¢æ‰èƒ½å®Œå…¨æ¶ˆè€—
            AVAudioFrameCount inputFramesProcessed = 0;
            
            while (inputFramesProcessed < inputBuffer.frameLength) {
                // è½¬æ¢ä¸ºPCM
                AVAudioPCMBuffer *outputBuffer = [[AVAudioPCMBuffer alloc] initWithPCMFormat:pcmFormat
                                                                                frameCapacity:outputCapacity];
                
                // ä½¿ç”¨æœ¬åœ°å˜é‡æ•è·å½“å‰çš„inputBuffer
                __block AVAudioPCMBuffer *currentInputBuffer = inputBuffer;
                __block BOOL inputProvided = NO;
                
                AVAudioConverterInputBlock inputBlock = ^AVAudioBuffer *(AVAudioPacketCount inNumberOfPackets, AVAudioConverterInputStatus *outStatus) {
                    if (!inputProvided && currentInputBuffer.frameLength > 0) {
                        inputProvided = YES;
                        *outStatus = AVAudioConverterInputStatus_HaveData;
                        return currentInputBuffer;
                    } else {
                        *outStatus = AVAudioConverterInputStatus_NoDataNow;
                        return nil;
                    }
                };
                
                AVAudioConverterOutputStatus status = [converter convertToBuffer:outputBuffer
                                                                            error:&error
                                                           withInputFromBlock:inputBlock];
                
                // ğŸ”§ å…³é”®ä¿®å¤ï¼šæ— è®ºçŠ¶æ€å¦‚ä½•ï¼Œåªè¦æœ‰è¾“å‡ºæ•°æ®å°±ä¿å­˜
                if (outputBuffer.frameLength > 0) {
                    const int16_t *samples = (const int16_t *)outputBuffer.audioBufferList->mBuffers[0].mData;
                    NSUInteger length = outputBuffer.frameLength * sizeof(int16_t);
                    if (samples && length > 0) {
                        [pcmData appendBytes:samples length:length];
                        totalOutputFrames += outputBuffer.frameLength;
                    } else {
                        NSLog(@"âš ï¸ è¾“å‡ºbufferæ•°æ®æŒ‡é’ˆä¸ºç©ºï¼ŒçŠ¶æ€: %ld", (long)status);
                    }
                }
                
                // å¤„ç†ä¸åŒçš„è½¬æ¢çŠ¶æ€
                if (status == AVAudioConverterOutputStatus_HaveData) {
                    // è¿˜æœ‰æ•°æ®ï¼Œç»§ç»­è½¬æ¢è¿™ä¸ªbuffer
                    continue;
                } else if (status == AVAudioConverterOutputStatus_InputRanDry) {
                    // è¾“å…¥æ•°æ®å·²å®Œå…¨æ¶ˆè€—ï¼Œè¿›å…¥ä¸‹ä¸€æ‰¹
                    inputFramesProcessed = inputBuffer.frameLength;
                    break;
                } else if (status == AVAudioConverterOutputStatus_Error) {
                    NSLog(@"âŒ è½¬æ¢é”™è¯¯: %@", error);
                    inputFramesProcessed = inputBuffer.frameLength;
                    break;
                } else {
                    NSLog(@"âš ï¸ æœªé¢„æœŸçš„è½¬æ¢çŠ¶æ€: %ld", (long)status);
                    inputFramesProcessed = inputBuffer.frameLength;
                    break;
                }
            }
        }
        
        NSLog(@"âœ… è½¬æ¢å®Œæˆ: %u å¸§ (é¢„æœŸ: %u å¸§)", totalOutputFrames, expectedOutputFrames);
    } else {
        // æ ¼å¼åŒ¹é…ï¼Œç›´æ¥è¯»å–
        while (audioFile.framePosition < audioFile.length) {
            AVAudioPCMBuffer *buffer = [[AVAudioPCMBuffer alloc] initWithPCMFormat:pcmFormat
                                                                      frameCapacity:frameCapacity];
            
            [audioFile readIntoBuffer:buffer error:&error];
            if (error || buffer.frameLength == 0) {
                break;
            }
            
            // è¿½åŠ PCMæ•°æ®
            const int16_t *samples = (const int16_t *)buffer.audioBufferList->mBuffers[0].mData;
            NSUInteger length = buffer.frameLength * sizeof(int16_t);
            [pcmData appendBytes:samples length:length];
        }
    }
    
    return pcmData;
}

- (void)play {
    [self playFromTime:0.0];
}

// ğŸ†• ä»æŒ‡å®šæ—¶é—´å¼€å§‹æ’­æ”¾
- (void)playFromTime:(NSTimeInterval)startTime {
    if (!self.audioPlayer) {
        NSLog(@"âŒ æ²¡æœ‰åŠ è½½éŸ³é¢‘æ–‡ä»¶");
        return;
    }
    
    // è·å–ç³»ç»Ÿé‡‡æ ·ç‡
    AVAudioSession *audioSession = [AVAudioSession sharedInstance];
    double systemSampleRate = audioSession.sampleRate;
    
    // è®¾ç½®BGMè¯»å–ä½ç½®
    NSUInteger targetPosition = (NSUInteger)(startTime * systemSampleRate);
    if (targetPosition >= self.bgmPCMDataLength) {
        NSLog(@"âš ï¸ èµ·å§‹æ—¶é—´ %.2f è¶…å‡ºBGMé•¿åº¦ï¼Œé‡ç½®ä¸º0", startTime);
        targetPosition = 0;
        startTime = 0;
    }
    self.bgmReadPosition = targetPosition;
    
    // è®¾ç½®AVAudioPlayeræ’­æ”¾ä½ç½®
    self.audioPlayer.currentTime = startTime;
    
    // å¯ç”¨å˜é€Ÿæ’­æ”¾
    self.audioPlayer.enableRate = YES;
    self.audioPlayer.volume = self.bgmVolume;
    self.audioPlayer.rate = 1.0;  // æ­£å¸¸é€Ÿåº¦
    
    [self.audioPlayer play];
    self.isPlaying = YES;
    
    NSLog(@"ğŸµ ä» %.2f ç§’å¼€å§‹æ’­æ”¾ BGM", startTime);
    NSLog(@"   éŸ³é‡: %.0f%%", self.bgmVolume * 100);
    NSLog(@"   BGMè¯»å–ä½ç½®: %lu/%lu", (unsigned long)targetPosition, (unsigned long)self.bgmPCMDataLength);
}

- (void)pause {
    [self.audioPlayer pause];
    self.isPlaying = NO;
    NSLog(@"â¸ï¸ éŸ³é¢‘æš‚åœ");
}

- (void)stop {
    [self.audioPlayer stop];
    self.audioPlayer.currentTime = 0;
    self.isPlaying = NO;
    NSLog(@"â¹ï¸ éŸ³é¢‘åœæ­¢");
}

- (void)reset {
    NSLog(@"ğŸ”„ å¼€å§‹é‡ç½® KaraokeAudioEngine...");
    
    // 1. åœæ­¢å½•éŸ³ï¼ˆå¦‚æœæ­£åœ¨å½•éŸ³ï¼‰
    if (self.isRecording) {
        self.currentSegment = nil;  // ä¸¢å¼ƒå½“å‰æ®µè½
        self.isRecording = NO;
        self.isRecordingPaused = NO;
    }
    
    // 2. åœæ­¢æ’­æ”¾
    if (self.isPlaying) {
        [self stop];
    }
    
    // 3. é‡ç½® BGM æ’­æ”¾å™¨åˆ°å¼€å¤´
    if (self.audioPlayer) {
        self.audioPlayer.currentTime = 0;
        NSLog(@"   âœ… BGMæ’­æ”¾å™¨å·²é‡ç½®åˆ°å¼€å¤´");
    }
    
    // 4. é‡ç½® BGM è¯»å–ä½ç½®ï¼ˆåŸå­æ“ä½œï¼‰
    self.bgmReadPosition = 0;
    NSLog(@"   âœ… BGMè¯»å–ä½ç½®å·²é‡ç½®");
    
    // 5. ğŸ†• æ¸…ç©ºæ‰€æœ‰å½•éŸ³æ®µè½
    [self.recordingSegmentsInternal removeAllObjects];
    self.currentSegment = nil;
    NSLog(@"   âœ… å½•éŸ³æ®µè½å·²æ¸…ç©º");
    
    // 6. é‡ç½®å½•éŸ³æ–‡ä»¶è·¯å¾„ï¼ˆå‡†å¤‡æ–°å½•éŸ³ï¼‰
    self.recordingFilePath = nil;
    NSLog(@"   âœ… å½•éŸ³æ–‡ä»¶è·¯å¾„å·²æ¸…ç©º");
    
    // 7. é€šçŸ¥ä»£ç†
    [self notifySegmentsUpdate];
    
    NSLog(@"âœ… KaraokeAudioEngine é‡ç½®å®Œæˆï¼Œå¯ä»¥å¼€å§‹æ–°çš„å½•éŸ³");
}

#pragma mark - è€³è¿”æ§åˆ¶

- (void)setEarReturnEnabled:(BOOL)enabled {
    _enableEarReturn = enabled;
    NSLog(@"ğŸ§ è€³è¿”%@", enabled ? @"å¯ç”¨" : @"ç¦ç”¨");
}

- (void)setEarReturnVolume:(float)volume {
    _earReturnVolume = MAX(0.0, MIN(1.0, volume));
    NSLog(@"ğŸ§ è€³è¿”éŸ³é‡: %.0f%%", _earReturnVolume * 100);
}

- (void)setMicrophoneVolume:(float)volume {
    _microphoneVolume = MAX(0.0, MIN(1.0, volume));
    NSLog(@"ğŸ¤ éº¦å…‹é£éŸ³é‡: %.0f%%", _microphoneVolume * 100);
}

#pragma mark - éŸ³æ•ˆæ§åˆ¶

- (void)setVoiceEffect:(VoiceEffectType)effectType {
    if (self.voiceEffectProcessor) {
        [self.voiceEffectProcessor setPresetEffect:effectType];
    }
}

#pragma mark - æ’­æ”¾è¿›åº¦

// æ ¹æ® BGM è¯»å–ä½ç½®è®¡ç®—å½“å‰æ’­æ”¾æ—¶é—´
- (NSTimeInterval)currentPlaybackTime {
    if (self.bgmPCMDataLength == 0) {
        return 0.0;
    }
    
    // ğŸ”§ ä½¿ç”¨ç³»ç»Ÿå®é™…é‡‡æ ·ç‡è®¡ç®—æ—¶é—´
    AVAudioSession *audioSession = [AVAudioSession sharedInstance];
    double systemSampleRate = audioSession.sampleRate;
    
    NSUInteger currentPos = self.bgmReadPosition;
    return (NSTimeInterval)currentPos / systemSampleRate;
}

#pragma mark - AVAudioPlayerDelegate

- (void)audioPlayerDidFinishPlaying:(AVAudioPlayer *)player successfully:(BOOL)flag {
    NSLog(@"ğŸµ BGMæ’­æ”¾å®Œæˆ (æˆåŠŸ: %@)", flag ? @"æ˜¯" : @"å¦");
    
    // BGMæ’­æ”¾å®Œæˆï¼Œè‡ªåŠ¨åœæ­¢å½•éŸ³ï¼ˆå¦‚æœæ­£åœ¨å½•éŸ³ï¼‰
    if (self.isRecording) {
        NSLog(@"ğŸµ BGMæ’­æ”¾å®Œæˆï¼Œè‡ªåŠ¨åœæ­¢å½•éŸ³");
        [self stopRecording];
        
        // é€šçŸ¥ä»£ç†
        if ([self.delegate respondsToSelector:@selector(audioEngineDidFinishPlaying)]) {
            dispatch_async(dispatch_get_main_queue(), ^{
                [self.delegate audioEngineDidFinishPlaying];
            });
        }
    }
    
    self.isPlaying = NO;
}

#pragma mark - æ¸…ç†

- (void)dealloc {
    [self stopRecording];
    [self stop];
    
    // æ¸…ç†BGMèµ„æºï¼ˆä¸éœ€è¦é”ï¼‰
    self.bgmPCMData = nil;
    self.bgmAudioFile = nil;
    
    // ğŸ†• æ¸…ç†å½•éŸ³æ®µè½
    [self.recordingSegmentsInternal removeAllObjects];
    self.currentSegment = nil;
    
    // é‡Šæ”¾é¢„åˆ†é…çš„æ··éŸ³ç¼“å†²åŒº
    if (self.mixBuffer) {
        free(self.mixBuffer);
        self.mixBuffer = NULL;
    }
    
    if (self.auGraph) {
        AUGraphStop(self.auGraph);
        AUGraphUninitialize(self.auGraph);
        AUGraphClose(self.auGraph);
        DisposeAUGraph(self.auGraph);
    }
    
    NSLog(@"ğŸ—‘ï¸ KaraokeAudioEngine dealloc");
}

@end
